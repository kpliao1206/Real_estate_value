{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load public test data\n",
    "path = 'D:/永豐攻房戰/30_Public Dataset_Public Sumission Template_v2/public_dataset.csv'\n",
    "public_df = pd.read_csv(path)\n",
    "\n",
    "scaler_y = FunctionTransformer(np.log1p, np.expm1)\n",
    "\n",
    "city_group = public_df.groupby('縣市') # 依照縣市分組\n",
    "taipei_df = city_group.get_group('台北市')\n",
    "newtaipei_df = city_group.get_group('新北市')\n",
    "taoyuan_df = city_group.get_group('桃園市')\n",
    "taichung_df = city_group.get_group('台中市')\n",
    "tainan_df =  city_group.get_group('台南市')\n",
    "kaoshung_df = city_group.get_group('高雄市')\n",
    "main_six = ['台北市', '新北市', '桃園市', '台中市', '台南市', '高雄市']\n",
    "others_df = pd.concat([city_group.get_group(group) for group in city_group.groups if group not in main_six]) # 取得六都以外的縣市\n",
    "print('台北市:', len(taipei_df))\n",
    "print('新北市:', len(newtaipei_df))\n",
    "print('桃園市:', len(taoyuan_df))\n",
    "print('台中市:', len(taichung_df))\n",
    "print('台南市:', len(tainan_df))\n",
    "print('高雄市:', len(kaoshung_df))\n",
    "print('其他:', len(others_df))\n",
    "df_lst = [taipei_df, newtaipei_df, taoyuan_df, taichung_df, tainan_df, kaoshung_df, others_df] # 用來對ID\n",
    "\n",
    "# 將各組資料取出後 normalize, 並存到dict, 作為各網路 input\n",
    "input_dict = {}\n",
    "names = ['taipei', 'newtaipei', 'taoyuan', 'taichung', 'tainan', 'kaoshung', 'others']\n",
    "for i, df in enumerate(df_lst):\n",
    "    target = df[['單價']] # 1 target\n",
    "    target = target.to_numpy()\n",
    "    numeric_data = df[['土地面積', '移轉層次', '總樓層數', '屋齡', '建物面積', '車位面積', '車位個數', '橫坐標', '縱坐標', '主建物面積', '陽台面積', '附屬建物面積']] # 12 features\n",
    "    numeric_data = numeric_data.to_numpy()\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_X.fit(numeric_data)\n",
    "    X_scaled = scaler_X.transform(numeric_data)\n",
    "    input_dict[names[i]] = X_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "from ANN_model import Taipei_features12_NN, NewTaipei_features12_NN, Taoyuan_features12_NN, Taichung_features12_NN, Tainan_features12_NN, Kaoshung_features12_NN, Others_features12_NN\n",
    "\n",
    "model1 = Taipei_features12_NN()\n",
    "model2 = NewTaipei_features12_NN()\n",
    "model3 = Taoyuan_features12_NN()\n",
    "model4 = Taichung_features12_NN()\n",
    "model5 = Tainan_features12_NN()\n",
    "model6 = Kaoshung_features12_NN()\n",
    "model7 = Others_features12_NN()\n",
    "\n",
    "model1.load_state_dict(torch.load('Models/taipei_features12_model1.pt'))\n",
    "model2.load_state_dict(torch.load('Models/newtaipei_features12_model1.pt'))\n",
    "model3.load_state_dict(torch.load('Models/taoyuan_features12_model1.pt'))\n",
    "model4.load_state_dict(torch.load('Models/taichung_features12_model1.pt'))\n",
    "model5.load_state_dict(torch.load('Models/tainan_features12_model1_1.pt'))\n",
    "model6.load_state_dict(torch.load('Models/kaoshung_features12_model1.pt'))\n",
    "model7.load_state_dict(torch.load('Models/others_features12_model1.pt'))\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "model6.eval()\n",
    "model7.eval()\n",
    "\n",
    "# 各網路輸入對應的 input 預測\n",
    "pred_df_lst = []\n",
    "for i, model in enumerate([model1, model2, model3, model4, model5, model6, model7]):\n",
    "    input = torch.from_numpy(input_dict[names[i]]).type(torch.FloatTensor)\n",
    "    y_pred = scaler_y.inverse_transform(model(input).detach().numpy()) # 還原 log1p\n",
    "    y_pred_df = pd.DataFrame({'pred': y_pred})\n",
    "    pred_df_lst.append(pd.concat((df_lst[i][['ID']], y_pred_df), axis=1, ignore_index=True))\n",
    "merged_pred_df = pd.concat((pred_df_lst), axis=0, ignore_index=True) # 把所有預測df合併\n",
    "merged_pred_df "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
