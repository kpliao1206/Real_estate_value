{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ANN_model import Features12_NN\n",
    "from Dataset import Features12_dataset\n",
    "from Utils import loss_plot\n",
    "from torch.utils.data import DataLoader\n",
    "from Train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X = np.load('Numeric_feature_dataset/features12_norm_train.npy')\n",
    "y = np.load('Numeric_feature_dataset/target_train.npy')\n",
    "train_dataset = Features12_dataset(X, y, train=True, random_state=RANDOM_STATE)\n",
    "test_dataset = Features12_dataset(X, y, train=False, random_state=RANDOM_STATE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n",
      "[Epoch 1/1000] train_loss: 1.072, test_loss: 0.673 | train_mape: 38.98, test_mape: 30.97\n",
      "[Epoch 2/1000] train_loss: 0.743, test_loss: 0.596 | train_mape: 35.57, test_mape: 30.56\n",
      "[Epoch 3/1000] train_loss: 0.703, test_loss: 0.569 | train_mape: 34.08, test_mape: 29.33\n",
      "[Epoch 4/1000] train_loss: 0.657, test_loss: 0.461 | train_mape: 33.08, test_mape: 28.03\n",
      "[Epoch 5/1000] train_loss: 0.541, test_loss: 0.381 | train_mape: 31.68, test_mape: 26.37\n",
      "[Epoch 6/1000] train_loss: 0.447, test_loss: 0.334 | train_mape: 30.31, test_mape: 25.45\n",
      "[Epoch 7/1000] train_loss: 0.450, test_loss: 0.298 | train_mape: 29.35, test_mape: 24.71\n",
      "[Epoch 8/1000] train_loss: 0.461, test_loss: 0.497 | train_mape: 28.65, test_mape: 24.17\n",
      "[Epoch 9/1000] train_loss: 0.447, test_loss: 0.355 | train_mape: 28.06, test_mape: 23.60\n",
      "[Epoch 10/1000] train_loss: 0.405, test_loss: 0.349 | train_mape: 27.43, test_mape: 23.08\n",
      "[Epoch 11/1000] train_loss: 0.412, test_loss: 0.318 | train_mape: 26.95, test_mape: 22.56\n",
      "[Epoch 12/1000] train_loss: 0.401, test_loss: 0.294 | train_mape: 26.51, test_mape: 22.09\n",
      "[Epoch 13/1000] train_loss: 0.396, test_loss: 0.325 | train_mape: 26.13, test_mape: 21.87\n",
      "[Epoch 14/1000] train_loss: 0.382, test_loss: 0.317 | train_mape: 25.79, test_mape: 21.60\n",
      "[Epoch 15/1000] train_loss: 0.369, test_loss: 0.327 | train_mape: 25.48, test_mape: 21.43\n",
      "[Epoch 16/1000] train_loss: 0.374, test_loss: 0.269 | train_mape: 25.23, test_mape: 21.17\n",
      "[Epoch 17/1000] train_loss: 0.386, test_loss: 0.287 | train_mape: 25.01, test_mape: 20.99\n",
      "[Epoch 18/1000] train_loss: 0.361, test_loss: 0.314 | train_mape: 24.78, test_mape: 20.84\n",
      "[Epoch 19/1000] train_loss: 0.372, test_loss: 0.277 | train_mape: 24.61, test_mape: 20.76\n",
      "[Epoch 20/1000] train_loss: 0.372, test_loss: 0.339 | train_mape: 24.45, test_mape: 20.64\n",
      "[Epoch 21/1000] train_loss: 0.360, test_loss: 0.300 | train_mape: 24.30, test_mape: 20.58\n",
      "[Epoch 22/1000] train_loss: 0.367, test_loss: 0.269 | train_mape: 24.16, test_mape: 20.50\n",
      "[Epoch 23/1000] train_loss: 0.347, test_loss: 0.238 | train_mape: 24.03, test_mape: 20.41\n",
      "[Epoch 24/1000] train_loss: 0.361, test_loss: 0.387 | train_mape: 23.91, test_mape: 20.45\n",
      "[Epoch 25/1000] train_loss: 0.399, test_loss: 0.282 | train_mape: 23.84, test_mape: 20.39\n",
      "[Epoch 26/1000] train_loss: 0.385, test_loss: 0.278 | train_mape: 23.77, test_mape: 20.31\n",
      "[Epoch 27/1000] train_loss: 0.356, test_loss: 0.275 | train_mape: 23.67, test_mape: 20.26\n",
      "[Epoch 28/1000] train_loss: 0.343, test_loss: 0.310 | train_mape: 23.57, test_mape: 20.21\n",
      "[Epoch 29/1000] train_loss: 0.355, test_loss: 0.288 | train_mape: 23.47, test_mape: 20.15\n",
      "[Epoch 30/1000] train_loss: 0.371, test_loss: 0.369 | train_mape: 23.40, test_mape: 20.19\n",
      "[Epoch 31/1000] train_loss: 0.348, test_loss: 0.253 | train_mape: 23.33, test_mape: 20.12\n",
      "[Epoch 32/1000] train_loss: 0.348, test_loss: 0.330 | train_mape: 23.26, test_mape: 20.09\n",
      "[Epoch 33/1000] train_loss: 0.373, test_loss: 0.270 | train_mape: 23.21, test_mape: 20.03\n",
      "[Epoch 34/1000] train_loss: 0.334, test_loss: 0.313 | train_mape: 23.14, test_mape: 19.99\n",
      "[Epoch 35/1000] train_loss: 0.357, test_loss: 0.262 | train_mape: 23.08, test_mape: 19.95\n",
      "[Epoch 36/1000] train_loss: 0.351, test_loss: 0.293 | train_mape: 23.02, test_mape: 19.92\n",
      "[Epoch 37/1000] train_loss: 0.356, test_loss: 0.383 | train_mape: 22.97, test_mape: 19.88\n",
      "[Epoch 38/1000] train_loss: 0.361, test_loss: 0.325 | train_mape: 22.92, test_mape: 19.88\n",
      "[Epoch 39/1000] train_loss: 0.365, test_loss: 0.263 | train_mape: 22.87, test_mape: 19.84\n",
      "[Epoch 40/1000] train_loss: 0.348, test_loss: 0.269 | train_mape: 22.83, test_mape: 19.81\n",
      "[Epoch 41/1000] train_loss: 0.323, test_loss: 0.283 | train_mape: 22.77, test_mape: 19.80\n",
      "[Epoch 42/1000] train_loss: 0.358, test_loss: 0.303 | train_mape: 22.73, test_mape: 19.79\n",
      "[Epoch 43/1000] train_loss: 0.339, test_loss: 0.255 | train_mape: 22.68, test_mape: 19.77\n",
      "[Epoch 44/1000] train_loss: 0.348, test_loss: 0.407 | train_mape: 22.64, test_mape: 19.76\n",
      "[Epoch 45/1000] train_loss: 0.373, test_loss: 0.305 | train_mape: 22.62, test_mape: 19.73\n",
      "[Epoch 46/1000] train_loss: 0.334, test_loss: 0.249 | train_mape: 22.58, test_mape: 19.68\n",
      "[Epoch 47/1000] train_loss: 0.353, test_loss: 0.306 | train_mape: 22.55, test_mape: 19.67\n",
      "[Epoch 48/1000] train_loss: 0.354, test_loss: 0.312 | train_mape: 22.51, test_mape: 19.64\n",
      "[Epoch 49/1000] train_loss: 0.329, test_loss: 0.270 | train_mape: 22.47, test_mape: 19.60\n",
      "[Epoch 50/1000] train_loss: 0.330, test_loss: 0.298 | train_mape: 22.43, test_mape: 19.57\n",
      "[Epoch 51/1000] train_loss: 0.329, test_loss: 0.261 | train_mape: 22.39, test_mape: 19.53\n",
      "[Epoch 52/1000] train_loss: 0.346, test_loss: 0.266 | train_mape: 22.36, test_mape: 19.49\n",
      "[Epoch 53/1000] train_loss: 0.338, test_loss: 0.299 | train_mape: 22.33, test_mape: 19.46\n",
      "Epoch 00054: reducing learning rate of group 0 to 5.0000e-03.\n",
      "[Epoch 54/1000] train_loss: 0.325, test_loss: 0.278 | train_mape: 22.29, test_mape: 19.44\n",
      "[Epoch 55/1000] train_loss: 0.306, test_loss: 0.234 | train_mape: 22.26, test_mape: 19.39\n",
      "[Epoch 56/1000] train_loss: 0.288, test_loss: 0.224 | train_mape: 22.20, test_mape: 19.35\n",
      "[Epoch 57/1000] train_loss: 0.302, test_loss: 0.224 | train_mape: 22.16, test_mape: 19.31\n",
      "[Epoch 58/1000] train_loss: 0.289, test_loss: 0.261 | train_mape: 22.11, test_mape: 19.29\n",
      "[Epoch 59/1000] train_loss: 0.311, test_loss: 0.253 | train_mape: 22.07, test_mape: 19.25\n",
      "[Epoch 60/1000] train_loss: 0.301, test_loss: 0.272 | train_mape: 22.03, test_mape: 19.24\n",
      "[Epoch 61/1000] train_loss: 0.293, test_loss: 0.274 | train_mape: 21.99, test_mape: 19.25\n",
      "[Epoch 62/1000] train_loss: 0.302, test_loss: 0.219 | train_mape: 21.95, test_mape: 19.20\n",
      "[Epoch 63/1000] train_loss: 0.291, test_loss: 0.213 | train_mape: 21.91, test_mape: 19.16\n",
      "[Epoch 64/1000] train_loss: 0.291, test_loss: 0.201 | train_mape: 21.87, test_mape: 19.12\n",
      "[Epoch 65/1000] train_loss: 0.283, test_loss: 0.210 | train_mape: 21.82, test_mape: 19.09\n",
      "[Epoch 66/1000] train_loss: 0.288, test_loss: 0.205 | train_mape: 21.78, test_mape: 19.05\n",
      "[Epoch 67/1000] train_loss: 0.289, test_loss: 0.221 | train_mape: 21.74, test_mape: 19.02\n",
      "[Epoch 68/1000] train_loss: 0.294, test_loss: 0.236 | train_mape: 21.71, test_mape: 19.00\n",
      "[Epoch 69/1000] train_loss: 0.280, test_loss: 0.207 | train_mape: 21.67, test_mape: 18.97\n",
      "[Epoch 70/1000] train_loss: 0.293, test_loss: 0.228 | train_mape: 21.63, test_mape: 18.93\n",
      "[Epoch 71/1000] train_loss: 0.278, test_loss: 0.187 | train_mape: 21.60, test_mape: 18.90\n",
      "[Epoch 72/1000] train_loss: 0.281, test_loss: 0.199 | train_mape: 21.56, test_mape: 18.86\n",
      "[Epoch 73/1000] train_loss: 0.281, test_loss: 0.209 | train_mape: 21.52, test_mape: 18.83\n",
      "[Epoch 74/1000] train_loss: 0.285, test_loss: 0.195 | train_mape: 21.49, test_mape: 18.80\n",
      "[Epoch 75/1000] train_loss: 0.274, test_loss: 0.308 | train_mape: 21.45, test_mape: 18.77\n",
      "[Epoch 76/1000] train_loss: 0.350, test_loss: 0.245 | train_mape: 21.44, test_mape: 18.75\n",
      "[Epoch 77/1000] train_loss: 0.286, test_loss: 0.267 | train_mape: 21.41, test_mape: 18.73\n",
      "[Epoch 78/1000] train_loss: 0.295, test_loss: 0.204 | train_mape: 21.38, test_mape: 18.70\n",
      "[Epoch 79/1000] train_loss: 0.280, test_loss: 0.225 | train_mape: 21.35, test_mape: 18.68\n",
      "[Epoch 80/1000] train_loss: 0.281, test_loss: 0.223 | train_mape: 21.32, test_mape: 18.65\n",
      "[Epoch 81/1000] train_loss: 0.286, test_loss: 0.205 | train_mape: 21.29, test_mape: 18.62\n",
      "[Epoch 82/1000] train_loss: 0.275, test_loss: 0.229 | train_mape: 21.25, test_mape: 18.60\n",
      "[Epoch 83/1000] train_loss: 0.291, test_loss: 0.251 | train_mape: 21.23, test_mape: 18.58\n",
      "[Epoch 84/1000] train_loss: 0.271, test_loss: 0.200 | train_mape: 21.20, test_mape: 18.56\n",
      "Epoch 00085: reducing learning rate of group 0 to 2.5000e-03.\n",
      "[Epoch 85/1000] train_loss: 0.288, test_loss: 0.195 | train_mape: 21.17, test_mape: 18.56\n",
      "[Epoch 86/1000] train_loss: 0.283, test_loss: 0.194 | train_mape: 21.14, test_mape: 18.53\n",
      "[Epoch 87/1000] train_loss: 0.254, test_loss: 0.182 | train_mape: 21.11, test_mape: 18.50\n",
      "[Epoch 88/1000] train_loss: 0.267, test_loss: 0.205 | train_mape: 21.08, test_mape: 18.47\n",
      "[Epoch 89/1000] train_loss: 0.255, test_loss: 0.177 | train_mape: 21.05, test_mape: 18.43\n",
      "[Epoch 90/1000] train_loss: 0.246, test_loss: 0.167 | train_mape: 21.01, test_mape: 18.40\n",
      "[Epoch 91/1000] train_loss: 0.245, test_loss: 0.188 | train_mape: 20.98, test_mape: 18.38\n",
      "[Epoch 92/1000] train_loss: 0.254, test_loss: 0.177 | train_mape: 20.95, test_mape: 18.35\n",
      "[Epoch 93/1000] train_loss: 0.266, test_loss: 0.177 | train_mape: 20.92, test_mape: 18.32\n",
      "[Epoch 94/1000] train_loss: 0.254, test_loss: 0.172 | train_mape: 20.89, test_mape: 18.29\n",
      "[Epoch 95/1000] train_loss: 0.248, test_loss: 0.178 | train_mape: 20.86, test_mape: 18.27\n",
      "[Epoch 96/1000] train_loss: 0.243, test_loss: 0.185 | train_mape: 20.83, test_mape: 18.24\n",
      "[Epoch 97/1000] train_loss: 0.252, test_loss: 0.186 | train_mape: 20.80, test_mape: 18.22\n",
      "[Epoch 98/1000] train_loss: 0.256, test_loss: 0.189 | train_mape: 20.78, test_mape: 18.19\n",
      "[Epoch 99/1000] train_loss: 0.251, test_loss: 0.178 | train_mape: 20.75, test_mape: 18.17\n",
      "[Epoch 100/1000] train_loss: 0.242, test_loss: 0.176 | train_mape: 20.72, test_mape: 18.15\n",
      "[Epoch 101/1000] train_loss: 0.241, test_loss: 0.163 | train_mape: 20.69, test_mape: 18.12\n",
      "[Epoch 102/1000] train_loss: 0.248, test_loss: 0.157 | train_mape: 20.67, test_mape: 18.09\n",
      "[Epoch 103/1000] train_loss: 0.230, test_loss: 0.156 | train_mape: 20.64, test_mape: 18.07\n",
      "[Epoch 104/1000] train_loss: 0.244, test_loss: 0.173 | train_mape: 20.61, test_mape: 18.05\n",
      "[Epoch 105/1000] train_loss: 0.238, test_loss: 0.163 | train_mape: 20.59, test_mape: 18.02\n",
      "[Epoch 106/1000] train_loss: 0.249, test_loss: 0.158 | train_mape: 20.56, test_mape: 18.00\n",
      "[Epoch 107/1000] train_loss: 0.243, test_loss: 0.172 | train_mape: 20.54, test_mape: 17.98\n",
      "[Epoch 108/1000] train_loss: 0.236, test_loss: 0.173 | train_mape: 20.51, test_mape: 17.96\n",
      "[Epoch 109/1000] train_loss: 0.234, test_loss: 0.166 | train_mape: 20.49, test_mape: 17.93\n",
      "[Epoch 110/1000] train_loss: 0.246, test_loss: 0.154 | train_mape: 20.46, test_mape: 17.91\n",
      "[Epoch 111/1000] train_loss: 0.240, test_loss: 0.156 | train_mape: 20.44, test_mape: 17.89\n",
      "[Epoch 112/1000] train_loss: 0.246, test_loss: 0.152 | train_mape: 20.42, test_mape: 17.86\n",
      "[Epoch 113/1000] train_loss: 0.233, test_loss: 0.157 | train_mape: 20.39, test_mape: 17.85\n",
      "[Epoch 114/1000] train_loss: 0.243, test_loss: 0.160 | train_mape: 20.37, test_mape: 17.82\n",
      "[Epoch 115/1000] train_loss: 0.234, test_loss: 0.152 | train_mape: 20.35, test_mape: 17.80\n",
      "Epoch 00116: reducing learning rate of group 0 to 1.2500e-03.\n",
      "[Epoch 116/1000] train_loss: 0.235, test_loss: 0.163 | train_mape: 20.33, test_mape: 17.78\n",
      "[Epoch 117/1000] train_loss: 0.231, test_loss: 0.150 | train_mape: 20.30, test_mape: 17.76\n",
      "[Epoch 118/1000] train_loss: 0.222, test_loss: 0.149 | train_mape: 20.28, test_mape: 17.74\n",
      "[Epoch 119/1000] train_loss: 0.215, test_loss: 0.151 | train_mape: 20.26, test_mape: 17.72\n",
      "[Epoch 120/1000] train_loss: 0.224, test_loss: 0.147 | train_mape: 20.23, test_mape: 17.70\n",
      "[Epoch 121/1000] train_loss: 0.211, test_loss: 0.148 | train_mape: 20.21, test_mape: 17.68\n",
      "[Epoch 122/1000] train_loss: 0.217, test_loss: 0.145 | train_mape: 20.19, test_mape: 17.66\n",
      "[Epoch 123/1000] train_loss: 0.219, test_loss: 0.143 | train_mape: 20.16, test_mape: 17.64\n",
      "[Epoch 124/1000] train_loss: 0.221, test_loss: 0.147 | train_mape: 20.14, test_mape: 17.62\n",
      "[Epoch 125/1000] train_loss: 0.215, test_loss: 0.146 | train_mape: 20.12, test_mape: 17.60\n",
      "[Epoch 126/1000] train_loss: 0.218, test_loss: 0.150 | train_mape: 20.10, test_mape: 17.59\n",
      "[Epoch 127/1000] train_loss: 0.227, test_loss: 0.151 | train_mape: 20.08, test_mape: 17.57\n",
      "[Epoch 128/1000] train_loss: 0.212, test_loss: 0.146 | train_mape: 20.06, test_mape: 17.55\n",
      "[Epoch 129/1000] train_loss: 0.229, test_loss: 0.179 | train_mape: 20.04, test_mape: 17.53\n",
      "[Epoch 130/1000] train_loss: 0.224, test_loss: 0.148 | train_mape: 20.02, test_mape: 17.52\n",
      "[Epoch 131/1000] train_loss: 0.219, test_loss: 0.144 | train_mape: 20.00, test_mape: 17.50\n",
      "[Epoch 132/1000] train_loss: 0.214, test_loss: 0.139 | train_mape: 19.98, test_mape: 17.48\n",
      "[Epoch 133/1000] train_loss: 0.212, test_loss: 0.145 | train_mape: 19.96, test_mape: 17.46\n",
      "[Epoch 134/1000] train_loss: 0.219, test_loss: 0.152 | train_mape: 19.94, test_mape: 17.44\n",
      "[Epoch 135/1000] train_loss: 0.233, test_loss: 0.211 | train_mape: 19.92, test_mape: 17.43\n",
      "[Epoch 136/1000] train_loss: 0.231, test_loss: 0.149 | train_mape: 19.90, test_mape: 17.41\n",
      "[Epoch 137/1000] train_loss: 0.227, test_loss: 0.151 | train_mape: 19.88, test_mape: 17.39\n",
      "[Epoch 138/1000] train_loss: 0.218, test_loss: 0.146 | train_mape: 19.86, test_mape: 17.38\n",
      "[Epoch 139/1000] train_loss: 0.221, test_loss: 0.145 | train_mape: 19.85, test_mape: 17.36\n",
      "[Epoch 140/1000] train_loss: 0.217, test_loss: 0.140 | train_mape: 19.83, test_mape: 17.34\n",
      "[Epoch 141/1000] train_loss: 0.218, test_loss: 0.143 | train_mape: 19.81, test_mape: 17.33\n",
      "[Epoch 142/1000] train_loss: 0.220, test_loss: 0.139 | train_mape: 19.79, test_mape: 17.31\n",
      "[Epoch 143/1000] train_loss: 0.211, test_loss: 0.138 | train_mape: 19.77, test_mape: 17.30\n",
      "[Epoch 144/1000] train_loss: 0.211, test_loss: 0.141 | train_mape: 19.76, test_mape: 17.28\n",
      "[Epoch 145/1000] train_loss: 0.215, test_loss: 0.148 | train_mape: 19.74, test_mape: 17.27\n",
      "[Epoch 146/1000] train_loss: 0.219, test_loss: 0.144 | train_mape: 19.72, test_mape: 17.25\n",
      "Epoch 00147: reducing learning rate of group 0 to 6.2500e-04.\n",
      "[Epoch 147/1000] train_loss: 0.217, test_loss: 0.146 | train_mape: 19.71, test_mape: 17.23\n",
      "[Epoch 148/1000] train_loss: 0.211, test_loss: 0.138 | train_mape: 19.69, test_mape: 17.22\n",
      "[Epoch 149/1000] train_loss: 0.209, test_loss: 0.136 | train_mape: 19.67, test_mape: 17.20\n",
      "[Epoch 150/1000] train_loss: 0.207, test_loss: 0.136 | train_mape: 19.66, test_mape: 17.19\n",
      "[Epoch 151/1000] train_loss: 0.204, test_loss: 0.134 | train_mape: 19.64, test_mape: 17.17\n",
      "[Epoch 152/1000] train_loss: 0.206, test_loss: 0.136 | train_mape: 19.62, test_mape: 17.16\n",
      "[Epoch 153/1000] train_loss: 0.211, test_loss: 0.138 | train_mape: 19.61, test_mape: 17.15\n",
      "[Epoch 154/1000] train_loss: 0.211, test_loss: 0.140 | train_mape: 19.59, test_mape: 17.13\n",
      "[Epoch 155/1000] train_loss: 0.201, test_loss: 0.138 | train_mape: 19.57, test_mape: 17.12\n",
      "[Epoch 156/1000] train_loss: 0.211, test_loss: 0.133 | train_mape: 19.56, test_mape: 17.10\n",
      "[Epoch 157/1000] train_loss: 0.206, test_loss: 0.134 | train_mape: 19.54, test_mape: 17.09\n",
      "[Epoch 158/1000] train_loss: 0.205, test_loss: 0.137 | train_mape: 19.53, test_mape: 17.08\n",
      "[Epoch 159/1000] train_loss: 0.209, test_loss: 0.138 | train_mape: 19.51, test_mape: 17.06\n",
      "[Epoch 160/1000] train_loss: 0.211, test_loss: 0.138 | train_mape: 19.49, test_mape: 17.05\n",
      "[Epoch 161/1000] train_loss: 0.208, test_loss: 0.131 | train_mape: 19.48, test_mape: 17.04\n",
      "[Epoch 162/1000] train_loss: 0.204, test_loss: 0.130 | train_mape: 19.46, test_mape: 17.02\n",
      "[Epoch 163/1000] train_loss: 0.206, test_loss: 0.131 | train_mape: 19.45, test_mape: 17.01\n",
      "[Epoch 164/1000] train_loss: 0.210, test_loss: 0.137 | train_mape: 19.43, test_mape: 17.00\n",
      "[Epoch 165/1000] train_loss: 0.209, test_loss: 0.132 | train_mape: 19.42, test_mape: 16.99\n",
      "[Epoch 166/1000] train_loss: 0.204, test_loss: 0.133 | train_mape: 19.41, test_mape: 16.97\n",
      "[Epoch 167/1000] train_loss: 0.204, test_loss: 0.132 | train_mape: 19.39, test_mape: 16.96\n",
      "[Epoch 168/1000] train_loss: 0.209, test_loss: 0.135 | train_mape: 19.38, test_mape: 16.95\n",
      "[Epoch 169/1000] train_loss: 0.202, test_loss: 0.137 | train_mape: 19.36, test_mape: 16.94\n",
      "[Epoch 170/1000] train_loss: 0.206, test_loss: 0.132 | train_mape: 19.35, test_mape: 16.93\n",
      "[Epoch 171/1000] train_loss: 0.196, test_loss: 0.135 | train_mape: 19.33, test_mape: 16.92\n",
      "[Epoch 172/1000] train_loss: 0.207, test_loss: 0.132 | train_mape: 19.32, test_mape: 16.90\n",
      "[Epoch 173/1000] train_loss: 0.201, test_loss: 0.136 | train_mape: 19.31, test_mape: 16.89\n",
      "[Epoch 174/1000] train_loss: 0.209, test_loss: 0.133 | train_mape: 19.29, test_mape: 16.88\n",
      "[Epoch 175/1000] train_loss: 0.212, test_loss: 0.132 | train_mape: 19.28, test_mape: 16.87\n",
      "[Epoch 176/1000] train_loss: 0.203, test_loss: 0.130 | train_mape: 19.27, test_mape: 16.86\n",
      "[Epoch 177/1000] train_loss: 0.211, test_loss: 0.139 | train_mape: 19.26, test_mape: 16.85\n",
      "Epoch 00178: reducing learning rate of group 0 to 3.1250e-04.\n",
      "[Epoch 178/1000] train_loss: 0.213, test_loss: 0.129 | train_mape: 19.24, test_mape: 16.84\n",
      "[Epoch 179/1000] train_loss: 0.199, test_loss: 0.129 | train_mape: 19.23, test_mape: 16.83\n",
      "[Epoch 180/1000] train_loss: 0.199, test_loss: 0.128 | train_mape: 19.22, test_mape: 16.81\n",
      "[Epoch 181/1000] train_loss: 0.204, test_loss: 0.129 | train_mape: 19.21, test_mape: 16.80\n",
      "[Epoch 182/1000] train_loss: 0.199, test_loss: 0.131 | train_mape: 19.19, test_mape: 16.79\n",
      "[Epoch 183/1000] train_loss: 0.205, test_loss: 0.128 | train_mape: 19.18, test_mape: 16.78\n",
      "[Epoch 184/1000] train_loss: 0.204, test_loss: 0.129 | train_mape: 19.17, test_mape: 16.77\n",
      "[Epoch 185/1000] train_loss: 0.210, test_loss: 0.129 | train_mape: 19.16, test_mape: 16.76\n",
      "[Epoch 186/1000] train_loss: 0.203, test_loss: 0.130 | train_mape: 19.14, test_mape: 16.75\n",
      "[Epoch 187/1000] train_loss: 0.204, test_loss: 0.132 | train_mape: 19.13, test_mape: 16.74\n",
      "[Epoch 188/1000] train_loss: 0.203, test_loss: 0.129 | train_mape: 19.12, test_mape: 16.73\n",
      "[Epoch 189/1000] train_loss: 0.199, test_loss: 0.127 | train_mape: 19.11, test_mape: 16.72\n",
      "[Epoch 190/1000] train_loss: 0.204, test_loss: 0.130 | train_mape: 19.10, test_mape: 16.71\n",
      "[Epoch 191/1000] train_loss: 0.202, test_loss: 0.128 | train_mape: 19.09, test_mape: 16.70\n",
      "[Epoch 192/1000] train_loss: 0.202, test_loss: 0.130 | train_mape: 19.08, test_mape: 16.69\n",
      "[Epoch 193/1000] train_loss: 0.200, test_loss: 0.129 | train_mape: 19.06, test_mape: 16.68\n",
      "[Epoch 194/1000] train_loss: 0.199, test_loss: 0.129 | train_mape: 19.05, test_mape: 16.67\n",
      "[Epoch 195/1000] train_loss: 0.205, test_loss: 0.131 | train_mape: 19.04, test_mape: 16.66\n",
      "[Epoch 196/1000] train_loss: 0.196, test_loss: 0.130 | train_mape: 19.03, test_mape: 16.65\n",
      "[Epoch 197/1000] train_loss: 0.202, test_loss: 0.127 | train_mape: 19.02, test_mape: 16.64\n",
      "[Epoch 198/1000] train_loss: 0.199, test_loss: 0.126 | train_mape: 19.01, test_mape: 16.63\n",
      "[Epoch 199/1000] train_loss: 0.199, test_loss: 0.127 | train_mape: 19.00, test_mape: 16.62\n",
      "[Epoch 200/1000] train_loss: 0.195, test_loss: 0.128 | train_mape: 18.99, test_mape: 16.62\n",
      "[Epoch 201/1000] train_loss: 0.203, test_loss: 0.128 | train_mape: 18.98, test_mape: 16.61\n",
      "[Epoch 202/1000] train_loss: 0.192, test_loss: 0.127 | train_mape: 18.97, test_mape: 16.60\n",
      "[Epoch 203/1000] train_loss: 0.199, test_loss: 0.128 | train_mape: 18.96, test_mape: 16.59\n",
      "[Epoch 204/1000] train_loss: 0.200, test_loss: 0.128 | train_mape: 18.95, test_mape: 16.58\n",
      "[Epoch 205/1000] train_loss: 0.199, test_loss: 0.127 | train_mape: 18.94, test_mape: 16.57\n",
      "[Epoch 206/1000] train_loss: 0.197, test_loss: 0.134 | train_mape: 18.93, test_mape: 16.56\n",
      "[Epoch 207/1000] train_loss: 0.201, test_loss: 0.127 | train_mape: 18.92, test_mape: 16.56\n",
      "[Epoch 208/1000] train_loss: 0.200, test_loss: 0.126 | train_mape: 18.91, test_mape: 16.55\n",
      "Epoch 00209: reducing learning rate of group 0 to 1.5625e-04.\n",
      "[Epoch 209/1000] train_loss: 0.208, test_loss: 0.128 | train_mape: 18.90, test_mape: 16.54\n",
      "[Epoch 210/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.89, test_mape: 16.53\n",
      "[Epoch 211/1000] train_loss: 0.196, test_loss: 0.128 | train_mape: 18.88, test_mape: 16.52\n",
      "[Epoch 212/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.87, test_mape: 16.51\n",
      "[Epoch 213/1000] train_loss: 0.202, test_loss: 0.127 | train_mape: 18.86, test_mape: 16.51\n",
      "[Epoch 214/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.85, test_mape: 16.50\n",
      "[Epoch 215/1000] train_loss: 0.201, test_loss: 0.128 | train_mape: 18.84, test_mape: 16.49\n",
      "[Epoch 216/1000] train_loss: 0.201, test_loss: 0.127 | train_mape: 18.84, test_mape: 16.48\n",
      "[Epoch 217/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.83, test_mape: 16.48\n",
      "[Epoch 218/1000] train_loss: 0.199, test_loss: 0.126 | train_mape: 18.82, test_mape: 16.47\n",
      "[Epoch 219/1000] train_loss: 0.202, test_loss: 0.125 | train_mape: 18.81, test_mape: 16.46\n",
      "[Epoch 220/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.80, test_mape: 16.45\n",
      "[Epoch 221/1000] train_loss: 0.198, test_loss: 0.127 | train_mape: 18.79, test_mape: 16.44\n",
      "[Epoch 222/1000] train_loss: 0.195, test_loss: 0.126 | train_mape: 18.78, test_mape: 16.44\n",
      "[Epoch 223/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.77, test_mape: 16.43\n",
      "[Epoch 224/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 18.76, test_mape: 16.42\n",
      "[Epoch 225/1000] train_loss: 0.200, test_loss: 0.127 | train_mape: 18.75, test_mape: 16.41\n",
      "[Epoch 226/1000] train_loss: 0.192, test_loss: 0.129 | train_mape: 18.75, test_mape: 16.40\n",
      "[Epoch 227/1000] train_loss: 0.190, test_loss: 0.129 | train_mape: 18.74, test_mape: 16.40\n",
      "[Epoch 228/1000] train_loss: 0.197, test_loss: 0.129 | train_mape: 18.73, test_mape: 16.39\n",
      "[Epoch 229/1000] train_loss: 0.200, test_loss: 0.128 | train_mape: 18.72, test_mape: 16.38\n",
      "[Epoch 230/1000] train_loss: 0.201, test_loss: 0.127 | train_mape: 18.71, test_mape: 16.38\n",
      "[Epoch 231/1000] train_loss: 0.204, test_loss: 0.127 | train_mape: 18.71, test_mape: 16.37\n",
      "[Epoch 232/1000] train_loss: 0.205, test_loss: 0.129 | train_mape: 18.70, test_mape: 16.36\n",
      "[Epoch 233/1000] train_loss: 0.200, test_loss: 0.127 | train_mape: 18.69, test_mape: 16.36\n",
      "[Epoch 234/1000] train_loss: 0.204, test_loss: 0.130 | train_mape: 18.68, test_mape: 16.35\n",
      "[Epoch 235/1000] train_loss: 0.200, test_loss: 0.129 | train_mape: 18.68, test_mape: 16.34\n",
      "[Epoch 236/1000] train_loss: 0.203, test_loss: 0.129 | train_mape: 18.67, test_mape: 16.34\n",
      "[Epoch 237/1000] train_loss: 0.209, test_loss: 0.129 | train_mape: 18.66, test_mape: 16.33\n",
      "[Epoch 238/1000] train_loss: 0.191, test_loss: 0.130 | train_mape: 18.65, test_mape: 16.32\n",
      "[Epoch 239/1000] train_loss: 0.202, test_loss: 0.128 | train_mape: 18.65, test_mape: 16.32\n",
      "Epoch 00240: reducing learning rate of group 0 to 7.8125e-05.\n",
      "[Epoch 240/1000] train_loss: 0.196, test_loss: 0.129 | train_mape: 18.64, test_mape: 16.31\n",
      "[Epoch 241/1000] train_loss: 0.194, test_loss: 0.128 | train_mape: 18.63, test_mape: 16.30\n",
      "[Epoch 242/1000] train_loss: 0.196, test_loss: 0.128 | train_mape: 18.62, test_mape: 16.30\n",
      "[Epoch 243/1000] train_loss: 0.194, test_loss: 0.127 | train_mape: 18.62, test_mape: 16.29\n",
      "[Epoch 244/1000] train_loss: 0.198, test_loss: 0.127 | train_mape: 18.61, test_mape: 16.28\n",
      "[Epoch 245/1000] train_loss: 0.200, test_loss: 0.127 | train_mape: 18.60, test_mape: 16.28\n",
      "[Epoch 246/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.60, test_mape: 16.27\n",
      "[Epoch 247/1000] train_loss: 0.192, test_loss: 0.126 | train_mape: 18.59, test_mape: 16.26\n",
      "[Epoch 248/1000] train_loss: 0.189, test_loss: 0.127 | train_mape: 18.58, test_mape: 16.26\n",
      "[Epoch 249/1000] train_loss: 0.198, test_loss: 0.127 | train_mape: 18.57, test_mape: 16.25\n",
      "[Epoch 250/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.57, test_mape: 16.25\n",
      "[Epoch 251/1000] train_loss: 0.192, test_loss: 0.127 | train_mape: 18.56, test_mape: 16.24\n",
      "[Epoch 252/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 18.55, test_mape: 16.23\n",
      "[Epoch 253/1000] train_loss: 0.192, test_loss: 0.126 | train_mape: 18.55, test_mape: 16.23\n",
      "[Epoch 254/1000] train_loss: 0.195, test_loss: 0.127 | train_mape: 18.54, test_mape: 16.22\n",
      "[Epoch 255/1000] train_loss: 0.203, test_loss: 0.126 | train_mape: 18.53, test_mape: 16.22\n",
      "[Epoch 256/1000] train_loss: 0.189, test_loss: 0.127 | train_mape: 18.53, test_mape: 16.21\n",
      "[Epoch 257/1000] train_loss: 0.204, test_loss: 0.125 | train_mape: 18.52, test_mape: 16.20\n",
      "[Epoch 258/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 18.51, test_mape: 16.20\n",
      "[Epoch 259/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 18.51, test_mape: 16.19\n",
      "[Epoch 260/1000] train_loss: 0.193, test_loss: 0.126 | train_mape: 18.50, test_mape: 16.19\n",
      "[Epoch 261/1000] train_loss: 0.195, test_loss: 0.126 | train_mape: 18.49, test_mape: 16.18\n",
      "[Epoch 262/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.49, test_mape: 16.18\n",
      "[Epoch 263/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.48, test_mape: 16.17\n",
      "[Epoch 264/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 18.47, test_mape: 16.16\n",
      "[Epoch 265/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.47, test_mape: 16.16\n",
      "[Epoch 266/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.46, test_mape: 16.15\n",
      "[Epoch 267/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 18.45, test_mape: 16.15\n",
      "[Epoch 268/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.45, test_mape: 16.14\n",
      "[Epoch 269/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 18.44, test_mape: 16.14\n",
      "[Epoch 270/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 18.44, test_mape: 16.13\n",
      "Epoch 00271: reducing learning rate of group 0 to 3.9063e-05.\n",
      "[Epoch 271/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.43, test_mape: 16.12\n",
      "[Epoch 272/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 18.42, test_mape: 16.12\n",
      "[Epoch 273/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 18.42, test_mape: 16.11\n",
      "[Epoch 274/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 18.41, test_mape: 16.11\n",
      "[Epoch 275/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.41, test_mape: 16.10\n",
      "[Epoch 276/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.40, test_mape: 16.10\n",
      "[Epoch 277/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 18.40, test_mape: 16.09\n",
      "[Epoch 278/1000] train_loss: 0.203, test_loss: 0.126 | train_mape: 18.39, test_mape: 16.09\n",
      "[Epoch 279/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.38, test_mape: 16.08\n",
      "[Epoch 280/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.38, test_mape: 16.08\n",
      "[Epoch 281/1000] train_loss: 0.189, test_loss: 0.126 | train_mape: 18.37, test_mape: 16.07\n",
      "[Epoch 282/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.37, test_mape: 16.07\n",
      "[Epoch 283/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 18.36, test_mape: 16.06\n",
      "[Epoch 284/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.36, test_mape: 16.06\n",
      "[Epoch 285/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.35, test_mape: 16.05\n",
      "[Epoch 286/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.35, test_mape: 16.05\n",
      "[Epoch 287/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 18.34, test_mape: 16.04\n",
      "[Epoch 288/1000] train_loss: 0.192, test_loss: 0.126 | train_mape: 18.33, test_mape: 16.04\n",
      "[Epoch 289/1000] train_loss: 0.191, test_loss: 0.126 | train_mape: 18.33, test_mape: 16.03\n",
      "[Epoch 290/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.32, test_mape: 16.03\n",
      "[Epoch 291/1000] train_loss: 0.199, test_loss: 0.126 | train_mape: 18.32, test_mape: 16.03\n",
      "[Epoch 292/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.31, test_mape: 16.02\n",
      "[Epoch 293/1000] train_loss: 0.202, test_loss: 0.126 | train_mape: 18.31, test_mape: 16.02\n",
      "[Epoch 294/1000] train_loss: 0.200, test_loss: 0.126 | train_mape: 18.30, test_mape: 16.01\n",
      "[Epoch 295/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.30, test_mape: 16.01\n",
      "[Epoch 296/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 18.29, test_mape: 16.00\n",
      "[Epoch 297/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 18.29, test_mape: 16.00\n",
      "[Epoch 298/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.28, test_mape: 15.99\n",
      "[Epoch 299/1000] train_loss: 0.200, test_loss: 0.126 | train_mape: 18.28, test_mape: 15.99\n",
      "[Epoch 300/1000] train_loss: 0.190, test_loss: 0.126 | train_mape: 18.27, test_mape: 15.98\n",
      "[Epoch 301/1000] train_loss: 0.193, test_loss: 0.126 | train_mape: 18.27, test_mape: 15.98\n",
      "Epoch 00302: reducing learning rate of group 0 to 1.9531e-05.\n",
      "[Epoch 302/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.26, test_mape: 15.98\n",
      "[Epoch 303/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.26, test_mape: 15.97\n",
      "[Epoch 304/1000] train_loss: 0.204, test_loss: 0.126 | train_mape: 18.26, test_mape: 15.97\n",
      "[Epoch 305/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.25, test_mape: 15.96\n",
      "[Epoch 306/1000] train_loss: 0.193, test_loss: 0.126 | train_mape: 18.25, test_mape: 15.96\n",
      "[Epoch 307/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 18.24, test_mape: 15.96\n",
      "[Epoch 308/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 18.24, test_mape: 15.95\n",
      "[Epoch 309/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 18.23, test_mape: 15.95\n",
      "[Epoch 310/1000] train_loss: 0.195, test_loss: 0.126 | train_mape: 18.23, test_mape: 15.94\n",
      "[Epoch 311/1000] train_loss: 0.197, test_loss: 0.126 | train_mape: 18.22, test_mape: 15.94\n",
      "[Epoch 312/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.22, test_mape: 15.93\n",
      "[Epoch 313/1000] train_loss: 0.194, test_loss: 0.126 | train_mape: 18.21, test_mape: 15.93\n",
      "[Epoch 314/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.21, test_mape: 15.93\n",
      "[Epoch 315/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 18.20, test_mape: 15.92\n",
      "[Epoch 316/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 18.20, test_mape: 15.92\n",
      "[Epoch 317/1000] train_loss: 0.198, test_loss: 0.126 | train_mape: 18.20, test_mape: 15.91\n",
      "[Epoch 318/1000] train_loss: 0.196, test_loss: 0.126 | train_mape: 18.19, test_mape: 15.91\n",
      "[Epoch 319/1000] train_loss: 0.204, test_loss: 0.125 | train_mape: 18.19, test_mape: 15.91\n",
      "[Epoch 320/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.18, test_mape: 15.90\n",
      "[Epoch 321/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 18.18, test_mape: 15.90\n",
      "[Epoch 322/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.17, test_mape: 15.90\n",
      "[Epoch 323/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.17, test_mape: 15.89\n",
      "[Epoch 324/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 18.17, test_mape: 15.89\n",
      "[Epoch 325/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 18.16, test_mape: 15.88\n",
      "[Epoch 326/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.16, test_mape: 15.88\n",
      "[Epoch 327/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.15, test_mape: 15.88\n",
      "[Epoch 328/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.15, test_mape: 15.87\n",
      "[Epoch 329/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 18.14, test_mape: 15.87\n",
      "[Epoch 330/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.14, test_mape: 15.87\n",
      "[Epoch 331/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 18.14, test_mape: 15.86\n",
      "[Epoch 332/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 18.13, test_mape: 15.86\n",
      "Epoch 00333: reducing learning rate of group 0 to 9.7656e-06.\n",
      "[Epoch 333/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 18.13, test_mape: 15.85\n",
      "[Epoch 334/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 18.12, test_mape: 15.85\n",
      "[Epoch 335/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 18.12, test_mape: 15.85\n",
      "[Epoch 336/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 18.11, test_mape: 15.84\n",
      "[Epoch 337/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 18.11, test_mape: 15.84\n",
      "[Epoch 338/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.11, test_mape: 15.84\n",
      "[Epoch 339/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 18.10, test_mape: 15.83\n",
      "[Epoch 340/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 18.10, test_mape: 15.83\n",
      "[Epoch 341/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 18.10, test_mape: 15.83\n",
      "[Epoch 342/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 18.09, test_mape: 15.82\n",
      "[Epoch 343/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.09, test_mape: 15.82\n",
      "[Epoch 344/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 18.08, test_mape: 15.82\n",
      "[Epoch 345/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.08, test_mape: 15.81\n",
      "[Epoch 346/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 18.08, test_mape: 15.81\n",
      "[Epoch 347/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 18.07, test_mape: 15.81\n",
      "[Epoch 348/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 18.07, test_mape: 15.80\n",
      "[Epoch 349/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 18.07, test_mape: 15.80\n",
      "[Epoch 350/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 18.06, test_mape: 15.80\n",
      "[Epoch 351/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 18.06, test_mape: 15.79\n",
      "[Epoch 352/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.05, test_mape: 15.79\n",
      "[Epoch 353/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 18.05, test_mape: 15.79\n",
      "[Epoch 354/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.05, test_mape: 15.78\n",
      "[Epoch 355/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 18.04, test_mape: 15.78\n",
      "[Epoch 356/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 18.04, test_mape: 15.78\n",
      "[Epoch 357/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 18.04, test_mape: 15.77\n",
      "[Epoch 358/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 18.03, test_mape: 15.77\n",
      "[Epoch 359/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 18.03, test_mape: 15.77\n",
      "[Epoch 360/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 18.02, test_mape: 15.76\n",
      "[Epoch 361/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 18.02, test_mape: 15.76\n",
      "[Epoch 362/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 18.02, test_mape: 15.76\n",
      "[Epoch 363/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 18.01, test_mape: 15.76\n",
      "Epoch 00364: reducing learning rate of group 0 to 4.8828e-06.\n",
      "[Epoch 364/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 18.01, test_mape: 15.75\n",
      "[Epoch 365/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 18.01, test_mape: 15.75\n",
      "[Epoch 366/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 18.00, test_mape: 15.75\n",
      "[Epoch 367/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 18.00, test_mape: 15.74\n",
      "[Epoch 368/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 18.00, test_mape: 15.74\n",
      "[Epoch 369/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 18.00, test_mape: 15.74\n",
      "[Epoch 370/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.99, test_mape: 15.74\n",
      "[Epoch 371/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.99, test_mape: 15.73\n",
      "[Epoch 372/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.99, test_mape: 15.73\n",
      "[Epoch 373/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.98, test_mape: 15.73\n",
      "[Epoch 374/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.98, test_mape: 15.72\n",
      "[Epoch 375/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.98, test_mape: 15.72\n",
      "[Epoch 376/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.97, test_mape: 15.72\n",
      "[Epoch 377/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 17.97, test_mape: 15.72\n",
      "[Epoch 378/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.97, test_mape: 15.71\n",
      "[Epoch 379/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.96, test_mape: 15.71\n",
      "[Epoch 380/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.96, test_mape: 15.71\n",
      "[Epoch 381/1000] train_loss: 0.188, test_loss: 0.125 | train_mape: 17.96, test_mape: 15.70\n",
      "[Epoch 382/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.95, test_mape: 15.70\n",
      "[Epoch 383/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.95, test_mape: 15.70\n",
      "[Epoch 384/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.95, test_mape: 15.70\n",
      "[Epoch 385/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.94, test_mape: 15.69\n",
      "[Epoch 386/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.94, test_mape: 15.69\n",
      "[Epoch 387/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.94, test_mape: 15.69\n",
      "[Epoch 388/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.93, test_mape: 15.69\n",
      "[Epoch 389/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.93, test_mape: 15.68\n",
      "[Epoch 390/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.93, test_mape: 15.68\n",
      "[Epoch 391/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.93, test_mape: 15.68\n",
      "[Epoch 392/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.92, test_mape: 15.68\n",
      "[Epoch 393/1000] train_loss: 0.202, test_loss: 0.125 | train_mape: 17.92, test_mape: 15.67\n",
      "[Epoch 394/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.92, test_mape: 15.67\n",
      "Epoch 00395: reducing learning rate of group 0 to 2.4414e-06.\n",
      "[Epoch 395/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.91, test_mape: 15.67\n",
      "[Epoch 396/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.91, test_mape: 15.67\n",
      "[Epoch 397/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.91, test_mape: 15.66\n",
      "[Epoch 398/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.91, test_mape: 15.66\n",
      "[Epoch 399/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.90, test_mape: 15.66\n",
      "[Epoch 400/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.90, test_mape: 15.66\n",
      "[Epoch 401/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 17.90, test_mape: 15.65\n",
      "[Epoch 402/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.90, test_mape: 15.65\n",
      "[Epoch 403/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.89, test_mape: 15.65\n",
      "[Epoch 404/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.89, test_mape: 15.65\n",
      "[Epoch 405/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.89, test_mape: 15.64\n",
      "[Epoch 406/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.88, test_mape: 15.64\n",
      "[Epoch 407/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.88, test_mape: 15.64\n",
      "[Epoch 408/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.88, test_mape: 15.64\n",
      "[Epoch 409/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.88, test_mape: 15.63\n",
      "[Epoch 410/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.87, test_mape: 15.63\n",
      "[Epoch 411/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.87, test_mape: 15.63\n",
      "[Epoch 412/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.87, test_mape: 15.63\n",
      "[Epoch 413/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.87, test_mape: 15.62\n",
      "[Epoch 414/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.86, test_mape: 15.62\n",
      "[Epoch 415/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.86, test_mape: 15.62\n",
      "[Epoch 416/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.86, test_mape: 15.62\n",
      "[Epoch 417/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.86, test_mape: 15.62\n",
      "[Epoch 418/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.85, test_mape: 15.61\n",
      "[Epoch 419/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.85, test_mape: 15.61\n",
      "[Epoch 420/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.85, test_mape: 15.61\n",
      "[Epoch 421/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.85, test_mape: 15.61\n",
      "[Epoch 422/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.84, test_mape: 15.60\n",
      "[Epoch 423/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.84, test_mape: 15.60\n",
      "[Epoch 424/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.84, test_mape: 15.60\n",
      "[Epoch 425/1000] train_loss: 0.189, test_loss: 0.125 | train_mape: 17.84, test_mape: 15.60\n",
      "Epoch 00426: reducing learning rate of group 0 to 1.2207e-06.\n",
      "[Epoch 426/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.83, test_mape: 15.60\n",
      "[Epoch 427/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.83, test_mape: 15.59\n",
      "[Epoch 428/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.83, test_mape: 15.59\n",
      "[Epoch 429/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.83, test_mape: 15.59\n",
      "[Epoch 430/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.82, test_mape: 15.59\n",
      "[Epoch 431/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.82, test_mape: 15.58\n",
      "[Epoch 432/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.82, test_mape: 15.58\n",
      "[Epoch 433/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.82, test_mape: 15.58\n",
      "[Epoch 434/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.81, test_mape: 15.58\n",
      "[Epoch 435/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.81, test_mape: 15.58\n",
      "[Epoch 436/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.81, test_mape: 15.57\n",
      "[Epoch 437/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.81, test_mape: 15.57\n",
      "[Epoch 438/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.80, test_mape: 15.57\n",
      "[Epoch 439/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.80, test_mape: 15.57\n",
      "[Epoch 440/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.80, test_mape: 15.57\n",
      "[Epoch 441/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.80, test_mape: 15.56\n",
      "[Epoch 442/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.80, test_mape: 15.56\n",
      "[Epoch 443/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.79, test_mape: 15.56\n",
      "[Epoch 444/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.79, test_mape: 15.56\n",
      "[Epoch 445/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.79, test_mape: 15.56\n",
      "[Epoch 446/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.79, test_mape: 15.55\n",
      "[Epoch 447/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.79, test_mape: 15.55\n",
      "[Epoch 448/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.78, test_mape: 15.55\n",
      "[Epoch 449/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.78, test_mape: 15.55\n",
      "[Epoch 450/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.78, test_mape: 15.55\n",
      "[Epoch 451/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.78, test_mape: 15.54\n",
      "[Epoch 452/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.77, test_mape: 15.54\n",
      "[Epoch 453/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.77, test_mape: 15.54\n",
      "[Epoch 454/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.77, test_mape: 15.54\n",
      "[Epoch 455/1000] train_loss: 0.189, test_loss: 0.125 | train_mape: 17.77, test_mape: 15.54\n",
      "[Epoch 456/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.77, test_mape: 15.53\n",
      "Epoch 00457: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch 457/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.76, test_mape: 15.53\n",
      "[Epoch 458/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.76, test_mape: 15.53\n",
      "[Epoch 459/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.76, test_mape: 15.53\n",
      "[Epoch 460/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.76, test_mape: 15.53\n",
      "[Epoch 461/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.75, test_mape: 15.52\n",
      "[Epoch 462/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.75, test_mape: 15.52\n",
      "[Epoch 463/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.75, test_mape: 15.52\n",
      "[Epoch 464/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.75, test_mape: 15.52\n",
      "[Epoch 465/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.75, test_mape: 15.52\n",
      "[Epoch 466/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.74, test_mape: 15.52\n",
      "[Epoch 467/1000] train_loss: 0.201, test_loss: 0.124 | train_mape: 17.74, test_mape: 15.51\n",
      "[Epoch 468/1000] train_loss: 0.204, test_loss: 0.124 | train_mape: 17.74, test_mape: 15.51\n",
      "[Epoch 469/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.74, test_mape: 15.51\n",
      "[Epoch 470/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.74, test_mape: 15.51\n",
      "[Epoch 471/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.73, test_mape: 15.51\n",
      "[Epoch 472/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.73, test_mape: 15.50\n",
      "[Epoch 473/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.73, test_mape: 15.50\n",
      "[Epoch 474/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.73, test_mape: 15.50\n",
      "[Epoch 475/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.73, test_mape: 15.50\n",
      "[Epoch 476/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.73, test_mape: 15.50\n",
      "[Epoch 477/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.72, test_mape: 15.50\n",
      "[Epoch 478/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.72, test_mape: 15.49\n",
      "[Epoch 479/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.72, test_mape: 15.49\n",
      "[Epoch 480/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.72, test_mape: 15.49\n",
      "[Epoch 481/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.49\n",
      "[Epoch 482/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.49\n",
      "[Epoch 483/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.48\n",
      "[Epoch 484/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.48\n",
      "[Epoch 485/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.48\n",
      "[Epoch 486/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.71, test_mape: 15.48\n",
      "[Epoch 487/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.70, test_mape: 15.48\n",
      "[Epoch 488/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.70, test_mape: 15.48\n",
      "[Epoch 489/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.70, test_mape: 15.47\n",
      "[Epoch 490/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.70, test_mape: 15.47\n",
      "[Epoch 491/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.70, test_mape: 15.47\n",
      "[Epoch 492/1000] train_loss: 0.189, test_loss: 0.125 | train_mape: 17.69, test_mape: 15.47\n",
      "[Epoch 493/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.69, test_mape: 15.47\n",
      "[Epoch 494/1000] train_loss: 0.202, test_loss: 0.125 | train_mape: 17.69, test_mape: 15.47\n",
      "[Epoch 495/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.69, test_mape: 15.46\n",
      "[Epoch 496/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.69, test_mape: 15.46\n",
      "[Epoch 497/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.46\n",
      "[Epoch 498/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.46\n",
      "[Epoch 499/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.46\n",
      "[Epoch 500/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.46\n",
      "[Epoch 501/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.46\n",
      "[Epoch 502/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.68, test_mape: 15.45\n",
      "[Epoch 503/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.67, test_mape: 15.45\n",
      "[Epoch 504/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.67, test_mape: 15.45\n",
      "[Epoch 505/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.67, test_mape: 15.45\n",
      "[Epoch 506/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.67, test_mape: 15.45\n",
      "[Epoch 507/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.67, test_mape: 15.45\n",
      "[Epoch 508/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 509/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 510/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 511/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 512/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 513/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.66, test_mape: 15.44\n",
      "[Epoch 514/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.44\n",
      "[Epoch 515/1000] train_loss: 0.186, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.43\n",
      "[Epoch 516/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.43\n",
      "[Epoch 517/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.43\n",
      "[Epoch 518/1000] train_loss: 0.188, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.43\n",
      "[Epoch 519/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.65, test_mape: 15.43\n",
      "[Epoch 520/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.43\n",
      "[Epoch 521/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 522/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 523/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 524/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 525/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 526/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.64, test_mape: 15.42\n",
      "[Epoch 527/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 17.63, test_mape: 15.42\n",
      "[Epoch 528/1000] train_loss: 0.183, test_loss: 0.125 | train_mape: 17.63, test_mape: 15.41\n",
      "[Epoch 529/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.63, test_mape: 15.41\n",
      "[Epoch 530/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 17.63, test_mape: 15.41\n",
      "[Epoch 531/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.63, test_mape: 15.41\n",
      "[Epoch 532/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.41\n",
      "[Epoch 533/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.41\n",
      "[Epoch 534/1000] train_loss: 0.189, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.41\n",
      "[Epoch 535/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.40\n",
      "[Epoch 536/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.40\n",
      "[Epoch 537/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.62, test_mape: 15.40\n",
      "[Epoch 538/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.40\n",
      "[Epoch 539/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.40\n",
      "[Epoch 540/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.40\n",
      "[Epoch 541/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.40\n",
      "[Epoch 542/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.40\n",
      "[Epoch 543/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.39\n",
      "[Epoch 544/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.61, test_mape: 15.39\n",
      "[Epoch 545/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.60, test_mape: 15.39\n",
      "[Epoch 546/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.60, test_mape: 15.39\n",
      "[Epoch 547/1000] train_loss: 0.203, test_loss: 0.125 | train_mape: 17.60, test_mape: 15.39\n",
      "[Epoch 548/1000] train_loss: 0.204, test_loss: 0.125 | train_mape: 17.60, test_mape: 15.39\n",
      "[Epoch 549/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.60, test_mape: 15.39\n",
      "[Epoch 550/1000] train_loss: 0.186, test_loss: 0.125 | train_mape: 17.60, test_mape: 15.38\n",
      "[Epoch 551/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 552/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 553/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 554/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 555/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 556/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 557/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.59, test_mape: 15.38\n",
      "[Epoch 558/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 559/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 560/1000] train_loss: 0.205, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 561/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 562/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 563/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 564/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.58, test_mape: 15.37\n",
      "[Epoch 565/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.37\n",
      "[Epoch 566/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 567/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 568/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 569/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 570/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 571/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.57, test_mape: 15.36\n",
      "[Epoch 572/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.36\n",
      "[Epoch 573/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.36\n",
      "[Epoch 574/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 575/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 576/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 577/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 578/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 579/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.56, test_mape: 15.35\n",
      "[Epoch 580/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.35\n",
      "[Epoch 581/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.35\n",
      "[Epoch 582/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 583/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 584/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 585/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 586/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 587/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.55, test_mape: 15.34\n",
      "[Epoch 588/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.34\n",
      "[Epoch 589/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.34\n",
      "[Epoch 590/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.34\n",
      "[Epoch 591/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.33\n",
      "[Epoch 592/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.33\n",
      "[Epoch 593/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.33\n",
      "[Epoch 594/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.33\n",
      "[Epoch 595/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.54, test_mape: 15.33\n",
      "[Epoch 596/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.33\n",
      "[Epoch 597/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.33\n",
      "[Epoch 598/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.33\n",
      "[Epoch 599/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.33\n",
      "[Epoch 600/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.32\n",
      "[Epoch 601/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.32\n",
      "[Epoch 602/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.53, test_mape: 15.32\n",
      "[Epoch 603/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 604/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 605/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 606/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 607/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 608/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.32\n",
      "[Epoch 609/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.31\n",
      "[Epoch 610/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.52, test_mape: 15.31\n",
      "[Epoch 611/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 612/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 613/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 614/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 615/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 616/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 617/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.31\n",
      "[Epoch 618/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.30\n",
      "[Epoch 619/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.51, test_mape: 15.30\n",
      "[Epoch 620/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 621/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 622/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 623/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 624/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 625/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 626/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 627/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.50, test_mape: 15.30\n",
      "[Epoch 628/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 629/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 630/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 631/1000] train_loss: 0.187, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 632/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 633/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 634/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 635/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.49, test_mape: 15.29\n",
      "[Epoch 636/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.29\n",
      "[Epoch 637/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.29\n",
      "[Epoch 638/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 639/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 640/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 641/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 642/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 643/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 644/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.48, test_mape: 15.28\n",
      "[Epoch 645/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.28\n",
      "[Epoch 646/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.28\n",
      "[Epoch 647/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.28\n",
      "[Epoch 648/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.28\n",
      "[Epoch 649/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 650/1000] train_loss: 0.187, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 651/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 652/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 653/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 654/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.47, test_mape: 15.27\n",
      "[Epoch 655/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.27\n",
      "[Epoch 656/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.27\n",
      "[Epoch 657/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.27\n",
      "[Epoch 658/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.27\n",
      "[Epoch 659/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.27\n",
      "[Epoch 660/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.26\n",
      "[Epoch 661/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.26\n",
      "[Epoch 662/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.26\n",
      "[Epoch 663/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.26\n",
      "[Epoch 664/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.46, test_mape: 15.26\n",
      "[Epoch 665/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 666/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 667/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 668/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 669/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 670/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.26\n",
      "[Epoch 671/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.25\n",
      "[Epoch 672/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.25\n",
      "[Epoch 673/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.45, test_mape: 15.25\n",
      "[Epoch 674/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 675/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 676/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 677/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 678/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 679/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 680/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 681/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.25\n",
      "[Epoch 682/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.24\n",
      "[Epoch 683/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.44, test_mape: 15.24\n",
      "[Epoch 684/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 685/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 686/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 687/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 688/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 689/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 690/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 691/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 692/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 693/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.24\n",
      "[Epoch 694/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.43, test_mape: 15.23\n",
      "[Epoch 695/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 696/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 697/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 698/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 699/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 700/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 701/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 702/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 703/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 704/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 705/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.42, test_mape: 15.23\n",
      "[Epoch 706/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.23\n",
      "[Epoch 707/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 708/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 709/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 710/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 711/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 712/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 713/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 714/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 715/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.41, test_mape: 15.22\n",
      "[Epoch 716/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.22\n",
      "[Epoch 717/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.22\n",
      "[Epoch 718/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.22\n",
      "[Epoch 719/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 720/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 721/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 722/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 723/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 724/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 725/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 726/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.40, test_mape: 15.21\n",
      "[Epoch 727/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.21\n",
      "[Epoch 728/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.21\n",
      "[Epoch 729/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.21\n",
      "[Epoch 730/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.21\n",
      "[Epoch 731/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.21\n",
      "[Epoch 732/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 733/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 734/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 735/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 736/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 737/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 738/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 739/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.39, test_mape: 15.20\n",
      "[Epoch 740/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 741/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 742/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 743/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 744/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 745/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.20\n",
      "[Epoch 746/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 747/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 748/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 749/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 750/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 751/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 752/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.38, test_mape: 15.19\n",
      "[Epoch 753/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 754/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 755/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 756/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 757/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 758/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 759/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.19\n",
      "[Epoch 760/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.18\n",
      "[Epoch 761/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.18\n",
      "[Epoch 762/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.18\n",
      "[Epoch 763/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.18\n",
      "[Epoch 764/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.37, test_mape: 15.18\n",
      "[Epoch 765/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 766/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 767/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 768/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 769/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 770/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 771/1000] train_loss: 0.204, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 772/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 773/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 774/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.18\n",
      "[Epoch 775/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.17\n",
      "[Epoch 776/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.17\n",
      "[Epoch 777/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.17\n",
      "[Epoch 778/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.36, test_mape: 15.17\n",
      "[Epoch 779/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 780/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 781/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 782/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 783/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 784/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 785/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 786/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 787/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 788/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 789/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 790/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.17\n",
      "[Epoch 791/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.35, test_mape: 15.16\n",
      "[Epoch 792/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 793/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 794/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 795/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 796/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 797/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 798/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 799/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 800/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 801/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 802/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 803/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 804/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 805/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.34, test_mape: 15.16\n",
      "[Epoch 806/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.16\n",
      "[Epoch 807/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 808/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 809/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 810/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 811/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 812/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 813/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 814/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 815/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 816/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 817/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 818/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 819/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 820/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.33, test_mape: 15.15\n",
      "[Epoch 821/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.15\n",
      "[Epoch 822/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.15\n",
      "[Epoch 823/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.15\n",
      "[Epoch 824/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 825/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 826/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 827/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 828/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 829/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 830/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 831/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 832/1000] train_loss: 0.203, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 833/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 834/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 835/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.32, test_mape: 15.14\n",
      "[Epoch 836/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.14\n",
      "[Epoch 837/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.14\n",
      "[Epoch 838/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.14\n",
      "[Epoch 839/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.14\n",
      "[Epoch 840/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.14\n",
      "[Epoch 841/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 842/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 843/1000] train_loss: 0.202, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 844/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 845/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 846/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 847/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 848/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 849/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 850/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 851/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.31, test_mape: 15.13\n",
      "[Epoch 852/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 853/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 854/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 855/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 856/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 857/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 858/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.13\n",
      "[Epoch 859/1000] train_loss: 0.200, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 860/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 861/1000] train_loss: 0.199, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 862/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 863/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 864/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 865/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 866/1000] train_loss: 0.201, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 867/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.30, test_mape: 15.12\n",
      "[Epoch 868/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 869/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 870/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 871/1000] train_loss: 0.190, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 872/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 873/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 874/1000] train_loss: 0.192, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 875/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 876/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 877/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.29, test_mape: 15.12\n",
      "[Epoch 878/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 879/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 880/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 881/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 882/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 883/1000] train_loss: 0.201, test_loss: 0.125 | train_mape: 17.29, test_mape: 15.11\n",
      "[Epoch 884/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 885/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 886/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 887/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 888/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 889/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 890/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 891/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 892/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 893/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 894/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 895/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 896/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.11\n",
      "[Epoch 897/1000] train_loss: 0.188, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.10\n",
      "[Epoch 898/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.10\n",
      "[Epoch 899/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.10\n",
      "[Epoch 900/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.10\n",
      "[Epoch 901/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.28, test_mape: 15.10\n",
      "[Epoch 902/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 903/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 904/1000] train_loss: 0.202, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 905/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 906/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 907/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 908/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 909/1000] train_loss: 0.189, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 910/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 911/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 912/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 913/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 914/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 915/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 916/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 917/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.10\n",
      "[Epoch 918/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.09\n",
      "[Epoch 919/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.09\n",
      "[Epoch 920/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.27, test_mape: 15.09\n",
      "[Epoch 921/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 922/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 923/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 924/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 925/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 926/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 927/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 928/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 929/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 930/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 931/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 932/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 933/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 934/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 935/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 936/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 937/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 938/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 939/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.26, test_mape: 15.09\n",
      "[Epoch 940/1000] train_loss: 0.204, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 941/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 942/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 943/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 944/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 945/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 946/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 947/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 948/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 949/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 950/1000] train_loss: 0.185, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 951/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 952/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 953/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 954/1000] train_loss: 0.194, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 955/1000] train_loss: 0.189, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 956/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 957/1000] train_loss: 0.188, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 958/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.25, test_mape: 15.08\n",
      "[Epoch 959/1000] train_loss: 0.198, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.08\n",
      "[Epoch 960/1000] train_loss: 0.193, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.08\n",
      "[Epoch 961/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.08\n",
      "[Epoch 962/1000] train_loss: 0.191, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.08\n",
      "[Epoch 963/1000] train_loss: 0.196, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.08\n",
      "[Epoch 964/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 965/1000] train_loss: 0.197, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 966/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 967/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 968/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 969/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 970/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 971/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 972/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 973/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 974/1000] train_loss: 0.198, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 975/1000] train_loss: 0.191, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 976/1000] train_loss: 0.195, test_loss: 0.124 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 977/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 978/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 979/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 980/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.24, test_mape: 15.07\n",
      "[Epoch 981/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 982/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 983/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 984/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 985/1000] train_loss: 0.190, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 986/1000] train_loss: 0.196, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 987/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.07\n",
      "[Epoch 988/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 989/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 990/1000] train_loss: 0.193, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 991/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 992/1000] train_loss: 0.199, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 993/1000] train_loss: 0.188, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 994/1000] train_loss: 0.197, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 995/1000] train_loss: 0.194, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 996/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 997/1000] train_loss: 0.195, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 998/1000] train_loss: 0.200, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 999/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "[Epoch 1000/1000] train_loss: 0.192, test_loss: 0.125 | train_mape: 17.23, test_mape: 15.06\n",
      "Training is end. Total trainig time: 72.4 minutes\n"
     ]
    }
   ],
   "source": [
    "model = Features12_NN()\n",
    "model_trained, trainloss, testloss = train_model(model, train_loader, test_loader, num_epochs=1000, lr=0.01, weight_decay=1e-2, factor=0.5, min_lr=1e-6, patience=30, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plot(trainloss, testloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
