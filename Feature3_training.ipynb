{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ANN_model import Features3_NN\n",
    "from Dataset import Features12_dataset\n",
    "from Utils import loss_plot\n",
    "from torch.utils.data import DataLoader\n",
    "from Train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X = np.load('Numeric_feature_dataset/features12_norm_train.npy')\n",
    "y = np.load('Numeric_feature_dataset/target_train.npy')\n",
    "X_new = np.concatenate((X[:, 5].reshape(-1, 1), X[:, 7].reshape(-1, 1), X[:, 8].reshape(-1, 1)), axis=1) # 車位面積, 橫坐標, 縱坐標\n",
    "train_dataset = Features12_dataset(X_new, y, train=True, random_state=RANDOM_STATE)\n",
    "test_dataset = Features12_dataset(X_new, y, train=False, random_state=RANDOM_STATE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] train_loss: 1.406, test_loss: 0.795 | train_mape: 43.85, test_mape: 31.71\n",
      "[Epoch 2/1000] train_loss: 0.882, test_loss: 0.756 | train_mape: 39.80, test_mape: 32.10\n",
      "[Epoch 3/1000] train_loss: 0.844, test_loss: 0.721 | train_mape: 38.51, test_mape: 31.68\n",
      "[Epoch 4/1000] train_loss: 0.794, test_loss: 0.671 | train_mape: 37.46, test_mape: 30.96\n",
      "[Epoch 5/1000] train_loss: 0.725, test_loss: 0.572 | train_mape: 36.37, test_mape: 30.17\n",
      "[Epoch 6/1000] train_loss: 0.626, test_loss: 0.463 | train_mape: 35.29, test_mape: 29.38\n",
      "[Epoch 7/1000] train_loss: 0.577, test_loss: 0.463 | train_mape: 34.30, test_mape: 28.86\n",
      "[Epoch 8/1000] train_loss: 0.544, test_loss: 0.424 | train_mape: 33.49, test_mape: 28.15\n",
      "[Epoch 9/1000] train_loss: 0.529, test_loss: 0.434 | train_mape: 32.82, test_mape: 27.66\n",
      "[Epoch 10/1000] train_loss: 0.522, test_loss: 0.411 | train_mape: 32.23, test_mape: 27.23\n",
      "[Epoch 11/1000] train_loss: 0.519, test_loss: 0.421 | train_mape: 31.75, test_mape: 26.95\n",
      "[Epoch 12/1000] train_loss: 0.507, test_loss: 0.407 | train_mape: 31.34, test_mape: 26.60\n",
      "[Epoch 13/1000] train_loss: 0.509, test_loss: 0.422 | train_mape: 31.01, test_mape: 26.48\n",
      "[Epoch 14/1000] train_loss: 0.490, test_loss: 0.404 | train_mape: 30.69, test_mape: 26.29\n",
      "[Epoch 15/1000] train_loss: 0.484, test_loss: 0.398 | train_mape: 30.41, test_mape: 26.16\n",
      "[Epoch 16/1000] train_loss: 0.480, test_loss: 0.401 | train_mape: 30.16, test_mape: 25.98\n",
      "[Epoch 17/1000] train_loss: 0.486, test_loss: 0.401 | train_mape: 29.94, test_mape: 25.87\n",
      "[Epoch 18/1000] train_loss: 0.471, test_loss: 0.412 | train_mape: 29.72, test_mape: 25.73\n",
      "[Epoch 19/1000] train_loss: 0.469, test_loss: 0.395 | train_mape: 29.54, test_mape: 25.64\n",
      "[Epoch 20/1000] train_loss: 0.475, test_loss: 0.391 | train_mape: 29.37, test_mape: 25.59\n",
      "[Epoch 21/1000] train_loss: 0.464, test_loss: 0.381 | train_mape: 29.21, test_mape: 25.48\n",
      "[Epoch 22/1000] train_loss: 0.455, test_loss: 0.371 | train_mape: 29.05, test_mape: 25.44\n",
      "[Epoch 23/1000] train_loss: 0.474, test_loss: 0.392 | train_mape: 28.93, test_mape: 25.36\n",
      "[Epoch 24/1000] train_loss: 0.469, test_loss: 0.387 | train_mape: 28.81, test_mape: 25.31\n",
      "[Epoch 25/1000] train_loss: 0.468, test_loss: 0.370 | train_mape: 28.70, test_mape: 25.27\n",
      "[Epoch 26/1000] train_loss: 0.447, test_loss: 0.389 | train_mape: 28.57, test_mape: 25.26\n",
      "[Epoch 27/1000] train_loss: 0.452, test_loss: 0.415 | train_mape: 28.47, test_mape: 25.16\n",
      "[Epoch 28/1000] train_loss: 0.451, test_loss: 0.410 | train_mape: 28.36, test_mape: 25.07\n",
      "[Epoch 29/1000] train_loss: 0.453, test_loss: 0.386 | train_mape: 28.27, test_mape: 25.08\n",
      "[Epoch 30/1000] train_loss: 0.455, test_loss: 0.390 | train_mape: 28.18, test_mape: 25.04\n",
      "[Epoch 31/1000] train_loss: 0.442, test_loss: 0.365 | train_mape: 28.09, test_mape: 24.97\n",
      "Epoch 00032: reducing learning rate of group 0 to 5.0000e-03.\n",
      "[Epoch 32/1000] train_loss: 0.447, test_loss: 0.376 | train_mape: 28.01, test_mape: 24.94\n",
      "[Epoch 33/1000] train_loss: 0.425, test_loss: 0.366 | train_mape: 27.92, test_mape: 24.89\n",
      "[Epoch 34/1000] train_loss: 0.432, test_loss: 0.369 | train_mape: 27.84, test_mape: 24.84\n",
      "[Epoch 35/1000] train_loss: 0.436, test_loss: 0.373 | train_mape: 27.76, test_mape: 24.78\n",
      "[Epoch 36/1000] train_loss: 0.433, test_loss: 0.381 | train_mape: 27.69, test_mape: 24.74\n",
      "[Epoch 37/1000] train_loss: 0.428, test_loss: 0.367 | train_mape: 27.62, test_mape: 24.71\n",
      "[Epoch 38/1000] train_loss: 0.431, test_loss: 0.371 | train_mape: 27.55, test_mape: 24.70\n",
      "[Epoch 39/1000] train_loss: 0.422, test_loss: 0.360 | train_mape: 27.49, test_mape: 24.66\n",
      "[Epoch 40/1000] train_loss: 0.432, test_loss: 0.366 | train_mape: 27.43, test_mape: 24.66\n",
      "[Epoch 41/1000] train_loss: 0.424, test_loss: 0.365 | train_mape: 27.37, test_mape: 24.65\n",
      "[Epoch 42/1000] train_loss: 0.422, test_loss: 0.368 | train_mape: 27.32, test_mape: 24.64\n",
      "[Epoch 43/1000] train_loss: 0.424, test_loss: 0.361 | train_mape: 27.26, test_mape: 24.62\n",
      "[Epoch 44/1000] train_loss: 0.433, test_loss: 0.368 | train_mape: 27.21, test_mape: 24.61\n",
      "[Epoch 45/1000] train_loss: 0.428, test_loss: 0.360 | train_mape: 27.17, test_mape: 24.59\n",
      "[Epoch 46/1000] train_loss: 0.430, test_loss: 0.357 | train_mape: 27.12, test_mape: 24.56\n",
      "[Epoch 47/1000] train_loss: 0.419, test_loss: 0.365 | train_mape: 27.07, test_mape: 24.51\n",
      "[Epoch 48/1000] train_loss: 0.417, test_loss: 0.364 | train_mape: 27.02, test_mape: 24.47\n",
      "[Epoch 49/1000] train_loss: 0.427, test_loss: 0.381 | train_mape: 26.98, test_mape: 24.44\n",
      "[Epoch 50/1000] train_loss: 0.429, test_loss: 0.360 | train_mape: 26.94, test_mape: 24.42\n",
      "[Epoch 51/1000] train_loss: 0.428, test_loss: 0.366 | train_mape: 26.91, test_mape: 24.40\n",
      "[Epoch 52/1000] train_loss: 0.415, test_loss: 0.360 | train_mape: 26.86, test_mape: 24.37\n",
      "[Epoch 53/1000] train_loss: 0.422, test_loss: 0.360 | train_mape: 26.83, test_mape: 24.35\n",
      "[Epoch 54/1000] train_loss: 0.418, test_loss: 0.374 | train_mape: 26.79, test_mape: 24.36\n",
      "[Epoch 55/1000] train_loss: 0.420, test_loss: 0.369 | train_mape: 26.75, test_mape: 24.34\n",
      "[Epoch 56/1000] train_loss: 0.419, test_loss: 0.355 | train_mape: 26.72, test_mape: 24.33\n",
      "[Epoch 57/1000] train_loss: 0.420, test_loss: 0.366 | train_mape: 26.69, test_mape: 24.31\n",
      "[Epoch 58/1000] train_loss: 0.417, test_loss: 0.350 | train_mape: 26.65, test_mape: 24.29\n",
      "[Epoch 59/1000] train_loss: 0.423, test_loss: 0.379 | train_mape: 26.62, test_mape: 24.27\n",
      "[Epoch 60/1000] train_loss: 0.410, test_loss: 0.349 | train_mape: 26.59, test_mape: 24.25\n",
      "[Epoch 61/1000] train_loss: 0.423, test_loss: 0.355 | train_mape: 26.56, test_mape: 24.24\n",
      "[Epoch 62/1000] train_loss: 0.415, test_loss: 0.352 | train_mape: 26.53, test_mape: 24.22\n",
      "Epoch 00063: reducing learning rate of group 0 to 2.5000e-03.\n",
      "[Epoch 63/1000] train_loss: 0.410, test_loss: 0.363 | train_mape: 26.50, test_mape: 24.19\n",
      "[Epoch 64/1000] train_loss: 0.407, test_loss: 0.345 | train_mape: 26.47, test_mape: 24.18\n",
      "[Epoch 65/1000] train_loss: 0.413, test_loss: 0.350 | train_mape: 26.44, test_mape: 24.16\n",
      "[Epoch 66/1000] train_loss: 0.411, test_loss: 0.350 | train_mape: 26.41, test_mape: 24.13\n",
      "[Epoch 67/1000] train_loss: 0.409, test_loss: 0.338 | train_mape: 26.39, test_mape: 24.11\n",
      "[Epoch 68/1000] train_loss: 0.401, test_loss: 0.356 | train_mape: 26.36, test_mape: 24.09\n",
      "[Epoch 69/1000] train_loss: 0.396, test_loss: 0.339 | train_mape: 26.33, test_mape: 24.08\n",
      "[Epoch 70/1000] train_loss: 0.399, test_loss: 0.336 | train_mape: 26.30, test_mape: 24.07\n",
      "[Epoch 71/1000] train_loss: 0.413, test_loss: 0.339 | train_mape: 26.28, test_mape: 24.06\n",
      "[Epoch 72/1000] train_loss: 0.395, test_loss: 0.333 | train_mape: 26.25, test_mape: 24.04\n",
      "[Epoch 73/1000] train_loss: 0.405, test_loss: 0.338 | train_mape: 26.23, test_mape: 24.03\n",
      "[Epoch 74/1000] train_loss: 0.408, test_loss: 0.336 | train_mape: 26.21, test_mape: 24.02\n",
      "[Epoch 75/1000] train_loss: 0.407, test_loss: 0.333 | train_mape: 26.19, test_mape: 24.00\n",
      "[Epoch 76/1000] train_loss: 0.398, test_loss: 0.339 | train_mape: 26.16, test_mape: 23.99\n",
      "[Epoch 77/1000] train_loss: 0.401, test_loss: 0.338 | train_mape: 26.14, test_mape: 23.98\n",
      "[Epoch 78/1000] train_loss: 0.396, test_loss: 0.334 | train_mape: 26.12, test_mape: 23.97\n",
      "[Epoch 79/1000] train_loss: 0.391, test_loss: 0.332 | train_mape: 26.09, test_mape: 23.96\n",
      "[Epoch 80/1000] train_loss: 0.400, test_loss: 0.330 | train_mape: 26.08, test_mape: 23.94\n",
      "[Epoch 81/1000] train_loss: 0.403, test_loss: 0.331 | train_mape: 26.05, test_mape: 23.93\n",
      "[Epoch 82/1000] train_loss: 0.398, test_loss: 0.335 | train_mape: 26.04, test_mape: 23.93\n",
      "[Epoch 83/1000] train_loss: 0.401, test_loss: 0.330 | train_mape: 26.02, test_mape: 23.91\n",
      "[Epoch 84/1000] train_loss: 0.403, test_loss: 0.328 | train_mape: 26.00, test_mape: 23.90\n",
      "[Epoch 85/1000] train_loss: 0.398, test_loss: 0.335 | train_mape: 25.98, test_mape: 23.89\n",
      "[Epoch 86/1000] train_loss: 0.404, test_loss: 0.330 | train_mape: 25.96, test_mape: 23.87\n",
      "[Epoch 87/1000] train_loss: 0.393, test_loss: 0.338 | train_mape: 25.95, test_mape: 23.86\n",
      "[Epoch 88/1000] train_loss: 0.395, test_loss: 0.336 | train_mape: 25.93, test_mape: 23.86\n",
      "[Epoch 89/1000] train_loss: 0.392, test_loss: 0.331 | train_mape: 25.91, test_mape: 23.85\n",
      "[Epoch 90/1000] train_loss: 0.398, test_loss: 0.335 | train_mape: 25.89, test_mape: 23.84\n",
      "[Epoch 91/1000] train_loss: 0.396, test_loss: 0.333 | train_mape: 25.87, test_mape: 23.82\n",
      "[Epoch 92/1000] train_loss: 0.390, test_loss: 0.325 | train_mape: 25.86, test_mape: 23.81\n",
      "[Epoch 93/1000] train_loss: 0.400, test_loss: 0.331 | train_mape: 25.84, test_mape: 23.80\n",
      "Epoch 00094: reducing learning rate of group 0 to 1.2500e-03.\n",
      "[Epoch 94/1000] train_loss: 0.388, test_loss: 0.346 | train_mape: 25.82, test_mape: 23.79\n",
      "[Epoch 95/1000] train_loss: 0.395, test_loss: 0.331 | train_mape: 25.81, test_mape: 23.79\n",
      "[Epoch 96/1000] train_loss: 0.394, test_loss: 0.326 | train_mape: 25.79, test_mape: 23.78\n",
      "[Epoch 97/1000] train_loss: 0.400, test_loss: 0.327 | train_mape: 25.78, test_mape: 23.77\n",
      "[Epoch 98/1000] train_loss: 0.394, test_loss: 0.329 | train_mape: 25.76, test_mape: 23.76\n",
      "[Epoch 99/1000] train_loss: 0.391, test_loss: 0.326 | train_mape: 25.75, test_mape: 23.75\n",
      "[Epoch 100/1000] train_loss: 0.396, test_loss: 0.326 | train_mape: 25.74, test_mape: 23.75\n",
      "[Epoch 101/1000] train_loss: 0.396, test_loss: 0.327 | train_mape: 25.72, test_mape: 23.74\n",
      "[Epoch 102/1000] train_loss: 0.386, test_loss: 0.325 | train_mape: 25.71, test_mape: 23.73\n",
      "[Epoch 103/1000] train_loss: 0.392, test_loss: 0.323 | train_mape: 25.69, test_mape: 23.72\n",
      "[Epoch 104/1000] train_loss: 0.400, test_loss: 0.326 | train_mape: 25.68, test_mape: 23.71\n",
      "[Epoch 105/1000] train_loss: 0.386, test_loss: 0.332 | train_mape: 25.66, test_mape: 23.71\n",
      "[Epoch 106/1000] train_loss: 0.400, test_loss: 0.326 | train_mape: 25.65, test_mape: 23.70\n",
      "[Epoch 107/1000] train_loss: 0.395, test_loss: 0.324 | train_mape: 25.64, test_mape: 23.70\n",
      "[Epoch 108/1000] train_loss: 0.396, test_loss: 0.324 | train_mape: 25.62, test_mape: 23.69\n",
      "[Epoch 109/1000] train_loss: 0.393, test_loss: 0.330 | train_mape: 25.61, test_mape: 23.69\n",
      "[Epoch 110/1000] train_loss: 0.396, test_loss: 0.324 | train_mape: 25.60, test_mape: 23.68\n",
      "[Epoch 111/1000] train_loss: 0.392, test_loss: 0.327 | train_mape: 25.59, test_mape: 23.67\n",
      "[Epoch 112/1000] train_loss: 0.395, test_loss: 0.330 | train_mape: 25.58, test_mape: 23.66\n",
      "[Epoch 113/1000] train_loss: 0.401, test_loss: 0.332 | train_mape: 25.57, test_mape: 23.66\n",
      "[Epoch 114/1000] train_loss: 0.396, test_loss: 0.336 | train_mape: 25.56, test_mape: 23.66\n",
      "[Epoch 115/1000] train_loss: 0.389, test_loss: 0.328 | train_mape: 25.55, test_mape: 23.65\n",
      "[Epoch 116/1000] train_loss: 0.389, test_loss: 0.327 | train_mape: 25.54, test_mape: 23.64\n",
      "[Epoch 117/1000] train_loss: 0.397, test_loss: 0.330 | train_mape: 25.53, test_mape: 23.64\n",
      "[Epoch 118/1000] train_loss: 0.382, test_loss: 0.326 | train_mape: 25.51, test_mape: 23.63\n",
      "[Epoch 119/1000] train_loss: 0.393, test_loss: 0.328 | train_mape: 25.50, test_mape: 23.63\n",
      "[Epoch 120/1000] train_loss: 0.395, test_loss: 0.330 | train_mape: 25.49, test_mape: 23.62\n",
      "[Epoch 121/1000] train_loss: 0.396, test_loss: 0.326 | train_mape: 25.48, test_mape: 23.62\n",
      "[Epoch 122/1000] train_loss: 0.395, test_loss: 0.325 | train_mape: 25.47, test_mape: 23.61\n",
      "[Epoch 123/1000] train_loss: 0.386, test_loss: 0.329 | train_mape: 25.46, test_mape: 23.60\n",
      "[Epoch 124/1000] train_loss: 0.387, test_loss: 0.325 | train_mape: 25.45, test_mape: 23.60\n",
      "Epoch 00125: reducing learning rate of group 0 to 6.2500e-04.\n",
      "[Epoch 125/1000] train_loss: 0.393, test_loss: 0.332 | train_mape: 25.44, test_mape: 23.59\n",
      "[Epoch 126/1000] train_loss: 0.394, test_loss: 0.322 | train_mape: 25.43, test_mape: 23.58\n",
      "[Epoch 127/1000] train_loss: 0.394, test_loss: 0.325 | train_mape: 25.42, test_mape: 23.58\n",
      "[Epoch 128/1000] train_loss: 0.382, test_loss: 0.323 | train_mape: 25.41, test_mape: 23.57\n",
      "[Epoch 129/1000] train_loss: 0.389, test_loss: 0.324 | train_mape: 25.40, test_mape: 23.57\n",
      "[Epoch 130/1000] train_loss: 0.390, test_loss: 0.323 | train_mape: 25.39, test_mape: 23.56\n",
      "[Epoch 131/1000] train_loss: 0.389, test_loss: 0.322 | train_mape: 25.39, test_mape: 23.56\n",
      "[Epoch 132/1000] train_loss: 0.383, test_loss: 0.321 | train_mape: 25.38, test_mape: 23.55\n",
      "[Epoch 133/1000] train_loss: 0.386, test_loss: 0.323 | train_mape: 25.37, test_mape: 23.55\n",
      "[Epoch 134/1000] train_loss: 0.387, test_loss: 0.322 | train_mape: 25.36, test_mape: 23.55\n",
      "[Epoch 135/1000] train_loss: 0.388, test_loss: 0.325 | train_mape: 25.35, test_mape: 23.55\n",
      "[Epoch 136/1000] train_loss: 0.393, test_loss: 0.323 | train_mape: 25.34, test_mape: 23.54\n",
      "[Epoch 137/1000] train_loss: 0.383, test_loss: 0.319 | train_mape: 25.33, test_mape: 23.53\n",
      "[Epoch 138/1000] train_loss: 0.386, test_loss: 0.321 | train_mape: 25.32, test_mape: 23.53\n",
      "[Epoch 139/1000] train_loss: 0.384, test_loss: 0.324 | train_mape: 25.32, test_mape: 23.52\n",
      "[Epoch 140/1000] train_loss: 0.391, test_loss: 0.322 | train_mape: 25.31, test_mape: 23.52\n",
      "[Epoch 141/1000] train_loss: 0.396, test_loss: 0.321 | train_mape: 25.30, test_mape: 23.51\n",
      "[Epoch 142/1000] train_loss: 0.395, test_loss: 0.321 | train_mape: 25.29, test_mape: 23.51\n",
      "[Epoch 143/1000] train_loss: 0.395, test_loss: 0.322 | train_mape: 25.29, test_mape: 23.50\n",
      "[Epoch 144/1000] train_loss: 0.390, test_loss: 0.323 | train_mape: 25.28, test_mape: 23.50\n",
      "[Epoch 145/1000] train_loss: 0.398, test_loss: 0.325 | train_mape: 25.28, test_mape: 23.50\n",
      "[Epoch 146/1000] train_loss: 0.395, test_loss: 0.325 | train_mape: 25.27, test_mape: 23.49\n",
      "[Epoch 147/1000] train_loss: 0.394, test_loss: 0.325 | train_mape: 25.26, test_mape: 23.49\n",
      "[Epoch 148/1000] train_loss: 0.381, test_loss: 0.323 | train_mape: 25.25, test_mape: 23.49\n",
      "[Epoch 149/1000] train_loss: 0.388, test_loss: 0.323 | train_mape: 25.25, test_mape: 23.48\n",
      "[Epoch 150/1000] train_loss: 0.394, test_loss: 0.324 | train_mape: 25.24, test_mape: 23.48\n",
      "[Epoch 151/1000] train_loss: 0.381, test_loss: 0.325 | train_mape: 25.23, test_mape: 23.48\n",
      "[Epoch 152/1000] train_loss: 0.401, test_loss: 0.324 | train_mape: 25.23, test_mape: 23.47\n",
      "[Epoch 153/1000] train_loss: 0.392, test_loss: 0.326 | train_mape: 25.22, test_mape: 23.47\n",
      "[Epoch 154/1000] train_loss: 0.396, test_loss: 0.325 | train_mape: 25.22, test_mape: 23.47\n",
      "[Epoch 155/1000] train_loss: 0.388, test_loss: 0.326 | train_mape: 25.21, test_mape: 23.46\n",
      "Epoch 00156: reducing learning rate of group 0 to 3.1250e-04.\n",
      "[Epoch 156/1000] train_loss: 0.392, test_loss: 0.324 | train_mape: 25.20, test_mape: 23.46\n",
      "[Epoch 157/1000] train_loss: 0.394, test_loss: 0.322 | train_mape: 25.20, test_mape: 23.46\n",
      "[Epoch 158/1000] train_loss: 0.395, test_loss: 0.325 | train_mape: 25.19, test_mape: 23.46\n",
      "[Epoch 159/1000] train_loss: 0.383, test_loss: 0.322 | train_mape: 25.19, test_mape: 23.45\n",
      "[Epoch 160/1000] train_loss: 0.383, test_loss: 0.324 | train_mape: 25.18, test_mape: 23.45\n",
      "[Epoch 161/1000] train_loss: 0.382, test_loss: 0.322 | train_mape: 25.17, test_mape: 23.45\n",
      "[Epoch 162/1000] train_loss: 0.397, test_loss: 0.323 | train_mape: 25.17, test_mape: 23.44\n",
      "[Epoch 163/1000] train_loss: 0.393, test_loss: 0.321 | train_mape: 25.16, test_mape: 23.44\n",
      "[Epoch 164/1000] train_loss: 0.385, test_loss: 0.322 | train_mape: 25.16, test_mape: 23.44\n",
      "[Epoch 165/1000] train_loss: 0.399, test_loss: 0.324 | train_mape: 25.15, test_mape: 23.43\n",
      "[Epoch 166/1000] train_loss: 0.401, test_loss: 0.324 | train_mape: 25.15, test_mape: 23.43\n",
      "[Epoch 167/1000] train_loss: 0.379, test_loss: 0.324 | train_mape: 25.14, test_mape: 23.43\n",
      "[Epoch 168/1000] train_loss: 0.391, test_loss: 0.321 | train_mape: 25.14, test_mape: 23.43\n",
      "[Epoch 169/1000] train_loss: 0.389, test_loss: 0.323 | train_mape: 25.13, test_mape: 23.42\n",
      "[Epoch 170/1000] train_loss: 0.394, test_loss: 0.322 | train_mape: 25.13, test_mape: 23.42\n",
      "[Epoch 171/1000] train_loss: 0.390, test_loss: 0.320 | train_mape: 25.12, test_mape: 23.42\n",
      "[Epoch 172/1000] train_loss: 0.392, test_loss: 0.321 | train_mape: 25.12, test_mape: 23.41\n",
      "[Epoch 173/1000] train_loss: 0.387, test_loss: 0.322 | train_mape: 25.11, test_mape: 23.41\n",
      "[Epoch 174/1000] train_loss: 0.389, test_loss: 0.323 | train_mape: 25.11, test_mape: 23.41\n",
      "[Epoch 175/1000] train_loss: 0.378, test_loss: 0.321 | train_mape: 25.10, test_mape: 23.40\n",
      "[Epoch 176/1000] train_loss: 0.393, test_loss: 0.322 | train_mape: 25.09, test_mape: 23.40\n",
      "[Epoch 177/1000] train_loss: 0.382, test_loss: 0.322 | train_mape: 25.09, test_mape: 23.40\n",
      "[Epoch 178/1000] train_loss: 0.391, test_loss: 0.321 | train_mape: 25.08, test_mape: 23.39\n",
      "[Epoch 179/1000] train_loss: 0.386, test_loss: 0.321 | train_mape: 25.08, test_mape: 23.39\n",
      "[Epoch 180/1000] train_loss: 0.377, test_loss: 0.322 | train_mape: 25.07, test_mape: 23.39\n",
      "[Epoch 181/1000] train_loss: 0.398, test_loss: 0.322 | train_mape: 25.07, test_mape: 23.38\n",
      "[Epoch 182/1000] train_loss: 0.384, test_loss: 0.322 | train_mape: 25.07, test_mape: 23.38\n",
      "[Epoch 183/1000] train_loss: 0.391, test_loss: 0.319 | train_mape: 25.06, test_mape: 23.38\n",
      "[Epoch 184/1000] train_loss: 0.386, test_loss: 0.320 | train_mape: 25.06, test_mape: 23.37\n",
      "[Epoch 185/1000] train_loss: 0.383, test_loss: 0.321 | train_mape: 25.05, test_mape: 23.37\n",
      "[Epoch 186/1000] train_loss: 0.388, test_loss: 0.323 | train_mape: 25.04, test_mape: 23.37\n",
      "Epoch 00187: reducing learning rate of group 0 to 1.5625e-04.\n",
      "[Epoch 187/1000] train_loss: 0.387, test_loss: 0.321 | train_mape: 25.04, test_mape: 23.36\n",
      "[Epoch 188/1000] train_loss: 0.391, test_loss: 0.321 | train_mape: 25.03, test_mape: 23.36\n",
      "[Epoch 189/1000] train_loss: 0.390, test_loss: 0.320 | train_mape: 25.03, test_mape: 23.36\n",
      "[Epoch 190/1000] train_loss: 0.389, test_loss: 0.320 | train_mape: 25.03, test_mape: 23.36\n",
      "[Epoch 191/1000] train_loss: 0.377, test_loss: 0.320 | train_mape: 25.02, test_mape: 23.35\n",
      "[Epoch 192/1000] train_loss: 0.389, test_loss: 0.320 | train_mape: 25.02, test_mape: 23.35\n",
      "[Epoch 193/1000] train_loss: 0.388, test_loss: 0.320 | train_mape: 25.01, test_mape: 23.35\n",
      "[Epoch 194/1000] train_loss: 0.400, test_loss: 0.321 | train_mape: 25.01, test_mape: 23.34\n",
      "[Epoch 195/1000] train_loss: 0.384, test_loss: 0.320 | train_mape: 25.00, test_mape: 23.34\n",
      "[Epoch 196/1000] train_loss: 0.381, test_loss: 0.320 | train_mape: 25.00, test_mape: 23.34\n",
      "[Epoch 197/1000] train_loss: 0.400, test_loss: 0.321 | train_mape: 24.99, test_mape: 23.34\n",
      "[Epoch 198/1000] train_loss: 0.395, test_loss: 0.321 | train_mape: 24.99, test_mape: 23.33\n",
      "[Epoch 199/1000] train_loss: 0.386, test_loss: 0.321 | train_mape: 24.99, test_mape: 23.33\n",
      "[Epoch 200/1000] train_loss: 0.394, test_loss: 0.321 | train_mape: 24.98, test_mape: 23.33\n",
      "[Epoch 201/1000] train_loss: 0.390, test_loss: 0.321 | train_mape: 24.98, test_mape: 23.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\永豐攻房戰\\Real_estate_value\\Feature3_training.ipynb 儲存格 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%B0%B8%E8%B1%90%E6%94%BB%E6%88%BF%E6%88%B0/Real_estate_value/Feature3_training.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Features3_NN()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%B0%B8%E8%B1%90%E6%94%BB%E6%88%BF%E6%88%B0/Real_estate_value/Feature3_training.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_trained, trainloss, testloss \u001b[39m=\u001b[39m train_model(model, train_loader, test_loader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m, factor\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, min_lr\u001b[39m=\u001b[39;49m\u001b[39m1e-6\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%B0%B8%E8%B1%90%E6%94%BB%E6%88%BF%E6%88%B0/Real_estate_value/Feature3_training.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_plot(trainloss, testloss)\n",
      "File \u001b[1;32md:\\永豐攻房戰\\Real_estate_value\\Train.py:65\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, num_epochs, lr, weight_decay, factor, min_lr, verbose, patience, threshold)\u001b[0m\n\u001b[0;32m     62\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     64\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m---> 65\u001b[0m test_loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     66\u001b[0m test_mape \u001b[39m=\u001b[39m mean_absolute_percentage_error(outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), targets\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     67\u001b[0m valid_losses\u001b[39m.\u001b[39mappend(test_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\python39\\lib\\site-packages\\torch\\nn\\functional.py:3292\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(\u001b[39minput\u001b[39m, target)\n\u001b[1;32m-> 3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Features3_NN()\n",
    "model_trained, trainloss, testloss = train_model(model, train_loader, test_loader, num_epochs=1000, lr=0.01, weight_decay=1e-2, factor=0.5, min_lr=1e-6, patience=30, threshold=0.01)\n",
    "loss_plot(trainloss, testloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
